{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Easy-text-preprocessing",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/M3-2018/blob/master/assignments/individual/Easy_text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "PM7_wuOAo-ke",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Easy text-preprocessing approaches\n",
        "\n",
        "- ##  Spacy and out of the box sentence embeddings\n",
        "- ##  SKlearn and ML-style count-tfidf-vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "lkMwXDsZUiht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imporr libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "# quick evaluation\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SoAtR1JQfhaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9f8b69f8-2b8f-4e42-e2b2-2115af09dc92"
      },
      "cell_type": "code",
      "source": [
        "# Download the small standard English language model\n",
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXK0HF0XfRul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load up the model, so we can use it\n",
        "\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_VAH7IsfmeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load up the data\n",
        "\n",
        "data = pd.read_csv('https://github.com/SDS-AAU/M3-2018/raw/master/assignments/individual/data/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ezDLe80hkaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# take a 1000 sample (because it's an example)\n",
        "\n",
        "data = data.sample(n=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7gcPTBff3gI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you run this just like that, it will take around 10min for the whole dataset\n",
        "\n",
        "data['spacy_sentence_vec'] = data['text'].map(lambda t: nlp(t).vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53D_L63FkcAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b259a804-f95f-45c6-dc40-62d7bb314000"
      },
      "cell_type": "code",
      "source": [
        "# the spacy_sentence_vec column now contains a vector representation of each sentence with 384 dimensions\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>spacy_sentence_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14147</th>\n",
              "      <td>id15567</td>\n",
              "      <td>Mr. Blackwood has a pair of tailor's shears, a...</td>\n",
              "      <td>EAP</td>\n",
              "      <td>[0.20423822, 0.7053059, 0.7660605, 1.2693121, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15276</th>\n",
              "      <td>id18142</td>\n",
              "      <td>That gland is the great sense organ of organs ...</td>\n",
              "      <td>HPL</td>\n",
              "      <td>[0.3282318, -0.2011276, 0.39009184, 1.2634265,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11247</th>\n",
              "      <td>id16883</td>\n",
              "      <td>His interest gradually veered away from the un...</td>\n",
              "      <td>HPL</td>\n",
              "      <td>[0.44190902, 0.07274222, 0.103103265, 1.167332...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14353</th>\n",
              "      <td>id16917</td>\n",
              "      <td>From the moment of my mother's death untill hi...</td>\n",
              "      <td>MWS</td>\n",
              "      <td>[0.51801, 0.39364424, 0.21461968, 1.3217521, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2739</th>\n",
              "      <td>id09897</td>\n",
              "      <td>When I mention his weakness I have allusion to...</td>\n",
              "      <td>EAP</td>\n",
              "      <td>[0.6794714, 0.32919943, 1.0377783, 0.80767155,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                               text author  \\\n",
              "14147  id15567  Mr. Blackwood has a pair of tailor's shears, a...    EAP   \n",
              "15276  id18142  That gland is the great sense organ of organs ...    HPL   \n",
              "11247  id16883  His interest gradually veered away from the un...    HPL   \n",
              "14353  id16917  From the moment of my mother's death untill hi...    MWS   \n",
              "2739   id09897  When I mention his weakness I have allusion to...    EAP   \n",
              "\n",
              "                                      spacy_sentence_vec  \n",
              "14147  [0.20423822, 0.7053059, 0.7660605, 1.2693121, ...  \n",
              "15276  [0.3282318, -0.2011276, 0.39009184, 1.2634265,...  \n",
              "11247  [0.44190902, 0.07274222, 0.103103265, 1.167332...  \n",
              "14353  [0.51801, 0.39364424, 0.21461968, 1.3217521, 0...  \n",
              "2739   [0.6794714, 0.32919943, 1.0377783, 0.80767155,...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "LhsEMdfThvFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is how we transform the sequence of lists in rows into a numpy array\n",
        "# We just use vstack - that stands for vertical stacking\n",
        "\n",
        "X = np.vstack(data['spacy_sentence_vec'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TEWczT4chv2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51cb0271-85ec-4c4e-a873-fd810d259593"
      },
      "cell_type": "code",
      "source": [
        "# As expected: a 1000 by 384 matrix\n",
        "\n",
        "X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "OGsSvL3siLS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# our y can be defined from the author column using a standard label_encoder\n",
        "\n",
        "y = labelencoder.fit_transform(data['author'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FQejHfkzqZcL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DONE - all you need to do if you run a simple deep neural network.\n",
        "\n",
        "Let's see if that works using a simle Logistic Regression as a baseline model"
      ]
    },
    {
      "metadata": {
        "id": "mCkzJR_3ioto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split into train-test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GWc86_XXijvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load up a classifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOygXUZvoLZc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# You can experiment with some fancier stuff if you want\n",
        "#from xgboost import XGBClassifier\n",
        "\n",
        "#classifier = XGBClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M03kdXpyi-xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "83e81d86-165d-461d-a7c0-371f8aeac041"
      },
      "cell_type": "code",
      "source": [
        "# Fit the model \n",
        "\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "VoEhBy89jNeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8f2c5290-7f6f-4409-875c-c7283ead4b50"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, classifier.predict(X_test), target_names=labelencoder.classes_))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        EAP       0.69      0.61      0.64        79\n",
            "        HPL       0.59      0.73      0.65        51\n",
            "        MWS       0.70      0.67      0.69        70\n",
            "\n",
            "avg / total       0.67      0.66      0.66       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I-Oe8JwTrLbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Approach 2, using sklearn "
      ]
    },
    {
      "metadata": {
        "id": "mF2lPoQxvk_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "                             use_idf=True, \n",
        "                             smooth_idf=True)\n",
        "X = vectorizer.fit_transform(data['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WH9le7YUr506",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Let's evaluate"
      ]
    },
    {
      "metadata": {
        "id": "6diXha0OryG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d6ddbdd5-f8bc-4036-e791-f3d0b9c747cd"
      },
      "cell_type": "code",
      "source": [
        "# Split into train-test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "\n",
        "# Load up a classifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Fit the model \n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, classifier.predict(X_test), target_names=labelencoder.classes_))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "        EAP       0.49      0.96      0.65        79\n",
            "        HPL       0.78      0.14      0.23        51\n",
            "        MWS       0.86      0.44      0.58        70\n",
            "\n",
            "avg / total       0.69      0.57      0.52       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1R67qL9cxe3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Or do first the count-step and also try dimensionality reduction... SVD = LSI"
      ]
    },
    {
      "metadata": {
        "id": "vvfTKU1ylfn6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This will tokenize and count up each and any text-chunk\n",
        "# Add a TFIDF transformer if you want to work from that end\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(data['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBOYtOkgmFh6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This can be added to reduce dimensionality (using SVC rather than PCA because of sparse matrix input)\n",
        "# Dimensionality reduction (not really helpful)\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=500, algorithm='randomized', n_iter=10, random_state=42)\n",
        "X = svd.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}