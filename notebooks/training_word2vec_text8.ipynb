{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training word2vec text8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/M3-2018/blob/master/notebooks/training_word2vec_text8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qWEUbS0b7rWZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training customized word embeddings\n",
        "\n",
        "Word embeddings became big around 2013 and are linked to [this paper](https://arxiv.org/abs/1301.3781) with the beautiful title \n",
        "*Efficient Estimation of Word Representations in Vector Space* by Tomas Mokolov et al. coming out of Google. This was the foundation of Word2Vec.\n",
        "\n",
        "The idea behind it is easiest summarized by the following quote: \n",
        "\n",
        "\n",
        "> *You shall know a word by the company it keeps (Firth, J. R. 1957:11)*\n",
        "\n",
        "Let me start with a fascinating example of word embeddings in practice. Below, you can see a figure from the paper: \n",
        "*Dynamic Word Embeddings for Evolving Semantic Discovery*. Here (in simple terms) the researchers estimated word vectors for from textual inputs in different time-frames. They picked out some terms and person that obviously changed *their company* over the years. Then they look at the relative position of these terms compared to terms that did not change much (anchors). If you are interested in this kind of research, check out [this blog](https://blog.acolyer.org/2018/02/22/dynamic-word-embeddings-for-evolving-semantic-discovery/) that describes the paper briefly or the [original paper](https://arxiv.org/abs/1703.00607).\n",
        "\n",
        "![alt text](https://adriancolyer.files.wordpress.com/2018/02/evolving-word-embeddings-fig-1.jpeg)\n",
        "\n",
        "Word embeddings allow us to create term representations that \"learn\" meaning from semantic and syntactic features. These models take a sequence of sentences as an input and scan for all individual terms that appear in the whole corpus and all their occurrences. Such contextual learning seems to be able to pick up non-trivial conceptual details and it is this class of models that today enable technologies such as chatbots, machine translation and much more.\n",
        "\n",
        "The early word embedding models were Word2Vec and [GloVe](https://nlp.stanford.edu/projects/glove/).\n",
        "In December 2017 Facebook presented [fastText](https://fasttext.cc/) (by the way - by 2017 Tomas Mikolov was working for Facebook and is one of the authors of the [paper](https://arxiv.org/abs/1607.04606) that introduces the research behind fastText). This model extends the idea of Word2Vec, enriching these vectors by information from sub-word elements. What does that mean? Words are not only defined by surrounding words but in addition also by the various syllables that make up the word. Why should that be a good idea? Well, now words such as *apple* and *apples* do not only get similar vectors due to them often sharing context but also because they are composed of the same sub-word elements. This comes in particularly handy when we are dealing with language that have a rich morphology such as Turkish or Russian.  This is also great when working with web-text, which is often messy and misspelt.\n",
        "\n",
        "The current state-of-the-art (April 2018!) is ELMo (Embeddings from Language Models) that further tackles the problem of contextuality and particularly polysemy, i.e. same term means something else in a different context. \n",
        "\n",
        "You can read more about the ins and outs of the current state of embedding models [here](https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a).\n",
        "\n",
        "Now the good news: You will find pre-trained vectors from all mentioned models online. They will do great in most cases. However, when working with specific tasks: Some obscure languages and/or specific technical jargon (finance talk), it is nice to know how to train such word-vectors.\n",
        "\n",
        "In this tutorial and on M3 we will not go further than fastText (2017-state-of-the-art should be good enough for us â€“ sorry). You are more than welcome to use other, more sophisticated, embeddings.\n",
        "\n",
        "\n",
        "In this tutorial we will train three embedding models:\n",
        "\n",
        "- Word2Vec on text8 - a sample of English Wikipedia\n",
        "- Word2Vec on the hate speech and toxic comments data\n",
        "- fastText on the toxic comments data\n",
        "\n",
        "Once trained, we will store the models\n"
      ]
    },
    {
      "metadata": {
        "id": "XJe4cEEVO3Kv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's start by installing Gensim that we know and love since M2\n",
        "\n",
        "\n",
        "#surpresses lots of output\n",
        "%%capture \n",
        "\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrbC_yLZYK9q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import pandas for tabular data\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# import gensim and the Word2Vec as well as FastText models\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, FastText"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X671bfH0Slau",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's downlaod all needed data (form different sources)\n",
        "%%capture \n",
        "\n",
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!wget https://github.com/t-davidson/hate-speech-and-offensive-language/raw/master/data/labeled_data.csv\n",
        "!wget http://sds-datacrunch.aau.dk/public/all.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrqP_ALFS7_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Also, we need to unzip text8 and our toxic-comments data\n",
        "%%capture \n",
        "\n",
        "#!unzip text8.zip\n",
        "!unzip all.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6fD420QVkKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We import logging to get informative outputs from Gensim training\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SNl_JViuRrVh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Word2Vec on text8\n",
        "\n",
        "in the following we will train the model step by step. In future, you can do things much faster\n",
        "\n",
        "- We first use the text8 wrapper to efficiently read the text8 file from disk. \n",
        "- Then we instantiate a Word2Vec model (with some parameters)\n",
        "- We build the vocabulary\n",
        "- Finally, we train it\n",
        "\n",
        "Once done, we can play a bit around with it."
      ]
    },
    {
      "metadata": {
        "id": "1q0jc0WPTDBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# connect to the text8 file on disk. Gensim has a number of wrappers for other filetypes and sources. \n",
        "# Obviopusely, for a many-gigabyte-wikipedia dump, you wouldn't load the whole thing into memory\n",
        "# But rather read it in line by line from disk.\n",
        "\n",
        "text8 = gensim.models.word2vec.Text8Corpus('text8', max_sentence_length=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8stKkrPyU82l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We instantiate the model. Words that appear less than 5 times are kicked out. \n",
        "# We will train over 3 iterations.\n",
        "\n",
        "model_text8 = Word2Vec(iter=3, min_count=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VjytE7UmVMek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "98664ef1-29fe-4eb4-d179-6d5fe7ff6fda"
      },
      "cell_type": "code",
      "source": [
        "# Let's build the vocabulary\n",
        "\n",
        "model_text8.build_vocab(text8)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 20:39:08,094 : INFO : collecting all words and their counts\n",
            "2018-11-03 20:39:08,100 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-11-03 20:39:13,701 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
            "2018-11-03 20:39:13,702 : INFO : Loading a fresh vocabulary\n",
            "2018-11-03 20:39:14,447 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
            "2018-11-03 20:39:14,449 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
            "2018-11-03 20:39:14,684 : INFO : deleting the raw counts dictionary of 253854 items\n",
            "2018-11-03 20:39:14,697 : INFO : sample=0.001 downsamples 38 most-common words\n",
            "2018-11-03 20:39:14,700 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
            "2018-11-03 20:39:15,013 : INFO : estimated required memory for 71290 words and 100 dimensions: 92677000 bytes\n",
            "2018-11-03 20:39:15,014 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "4SI2VHyxVQ2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1598
        },
        "outputId": "72e9fea1-ddb4-4cbf-d4b3-56a2b6ad1126"
      },
      "cell_type": "code",
      "source": [
        "# Now we can start the training\n",
        "\n",
        "model_text8.train(text8, total_examples=model_text8.corpus_count, epochs=3)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 20:41:11,590 : INFO : training model with 3 workers on 71290 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-11-03 20:41:12,609 : INFO : EPOCH 1 - PROGRESS: at 4.06% examples, 502655 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:13,635 : INFO : EPOCH 1 - PROGRESS: at 8.29% examples, 505036 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:14,658 : INFO : EPOCH 1 - PROGRESS: at 12.11% examples, 491411 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:15,679 : INFO : EPOCH 1 - PROGRESS: at 15.87% examples, 483510 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:16,683 : INFO : EPOCH 1 - PROGRESS: at 19.69% examples, 481828 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:17,690 : INFO : EPOCH 1 - PROGRESS: at 23.34% examples, 477614 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:18,716 : INFO : EPOCH 1 - PROGRESS: at 27.16% examples, 476481 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:19,738 : INFO : EPOCH 1 - PROGRESS: at 30.86% examples, 474388 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:20,753 : INFO : EPOCH 1 - PROGRESS: at 34.57% examples, 473091 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:21,759 : INFO : EPOCH 1 - PROGRESS: at 38.33% examples, 472661 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:22,763 : INFO : EPOCH 1 - PROGRESS: at 41.92% examples, 470437 words/s, in_qsize 6, out_qsize 2\n",
            "2018-11-03 20:41:23,801 : INFO : EPOCH 1 - PROGRESS: at 45.74% examples, 469807 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:24,815 : INFO : EPOCH 1 - PROGRESS: at 49.50% examples, 469576 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:25,821 : INFO : EPOCH 1 - PROGRESS: at 53.20% examples, 469003 words/s, in_qsize 4, out_qsize 0\n",
            "2018-11-03 20:41:26,824 : INFO : EPOCH 1 - PROGRESS: at 56.91% examples, 468707 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:27,846 : INFO : EPOCH 1 - PROGRESS: at 60.61% examples, 467875 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:28,860 : INFO : EPOCH 1 - PROGRESS: at 64.37% examples, 467696 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:29,862 : INFO : EPOCH 1 - PROGRESS: at 68.14% examples, 467843 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:30,870 : INFO : EPOCH 1 - PROGRESS: at 71.84% examples, 467446 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:31,872 : INFO : EPOCH 1 - PROGRESS: at 75.54% examples, 466902 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:32,875 : INFO : EPOCH 1 - PROGRESS: at 79.31% examples, 466539 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:33,877 : INFO : EPOCH 1 - PROGRESS: at 83.07% examples, 466584 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:34,893 : INFO : EPOCH 1 - PROGRESS: at 86.83% examples, 466382 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:35,894 : INFO : EPOCH 1 - PROGRESS: at 90.53% examples, 466398 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:36,912 : INFO : EPOCH 1 - PROGRESS: at 94.36% examples, 466296 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:37,920 : INFO : EPOCH 1 - PROGRESS: at 98.00% examples, 465647 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:38,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-03 20:41:38,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-03 20:41:38,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-03 20:41:38,437 : INFO : EPOCH - 1 : training on 17005207 raw words (12505540 effective words) took 26.8s, 465939 effective words/s\n",
            "2018-11-03 20:41:39,443 : INFO : EPOCH 2 - PROGRESS: at 3.64% examples, 456821 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:40,459 : INFO : EPOCH 2 - PROGRESS: at 7.52% examples, 463208 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:41,467 : INFO : EPOCH 2 - PROGRESS: at 11.29% examples, 462596 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:42,469 : INFO : EPOCH 2 - PROGRESS: at 14.93% examples, 460687 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:43,479 : INFO : EPOCH 2 - PROGRESS: at 18.69% examples, 461920 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:44,482 : INFO : EPOCH 2 - PROGRESS: at 22.46% examples, 463048 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:45,518 : INFO : EPOCH 2 - PROGRESS: at 26.22% examples, 462497 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:46,531 : INFO : EPOCH 2 - PROGRESS: at 29.98% examples, 463596 words/s, in_qsize 6, out_qsize 0\n",
            "2018-11-03 20:41:47,556 : INFO : EPOCH 2 - PROGRESS: at 33.69% examples, 462808 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:48,565 : INFO : EPOCH 2 - PROGRESS: at 37.39% examples, 462838 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:49,585 : INFO : EPOCH 2 - PROGRESS: at 41.15% examples, 462698 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:50,608 : INFO : EPOCH 2 - PROGRESS: at 44.91% examples, 462675 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:51,618 : INFO : EPOCH 2 - PROGRESS: at 48.68% examples, 463098 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:52,642 : INFO : EPOCH 2 - PROGRESS: at 52.38% examples, 462303 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:41:53,659 : INFO : EPOCH 2 - PROGRESS: at 56.14% examples, 462698 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:54,674 : INFO : EPOCH 2 - PROGRESS: at 59.85% examples, 462302 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:55,688 : INFO : EPOCH 2 - PROGRESS: at 63.61% examples, 462477 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:56,707 : INFO : EPOCH 2 - PROGRESS: at 67.37% examples, 462405 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:57,736 : INFO : EPOCH 2 - PROGRESS: at 71.19% examples, 462675 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:58,738 : INFO : EPOCH 2 - PROGRESS: at 74.96% examples, 462948 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:41:59,766 : INFO : EPOCH 2 - PROGRESS: at 78.78% examples, 462352 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:00,771 : INFO : EPOCH 2 - PROGRESS: at 82.42% examples, 461835 words/s, in_qsize 6, out_qsize 2\n",
            "2018-11-03 20:42:01,786 : INFO : EPOCH 2 - PROGRESS: at 86.07% examples, 461296 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:02,793 : INFO : EPOCH 2 - PROGRESS: at 89.77% examples, 461327 words/s, in_qsize 6, out_qsize 0\n",
            "2018-11-03 20:42:03,800 : INFO : EPOCH 2 - PROGRESS: at 93.47% examples, 461061 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:04,804 : INFO : EPOCH 2 - PROGRESS: at 97.18% examples, 460988 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:05,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-03 20:42:05,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-03 20:42:05,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-03 20:42:05,534 : INFO : EPOCH - 2 : training on 17005207 raw words (12502350 effective words) took 27.1s, 461490 effective words/s\n",
            "2018-11-03 20:42:06,556 : INFO : EPOCH 3 - PROGRESS: at 3.64% examples, 450623 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:07,563 : INFO : EPOCH 3 - PROGRESS: at 7.47% examples, 458676 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:08,570 : INFO : EPOCH 3 - PROGRESS: at 11.17% examples, 457369 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:09,575 : INFO : EPOCH 3 - PROGRESS: at 14.76% examples, 454703 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:10,588 : INFO : EPOCH 3 - PROGRESS: at 18.58% examples, 458371 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:11,591 : INFO : EPOCH 3 - PROGRESS: at 22.28% examples, 458872 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:12,593 : INFO : EPOCH 3 - PROGRESS: at 25.87% examples, 458172 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:13,600 : INFO : EPOCH 3 - PROGRESS: at 29.51% examples, 458082 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:14,608 : INFO : EPOCH 3 - PROGRESS: at 33.16% examples, 458132 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:15,620 : INFO : EPOCH 3 - PROGRESS: at 36.80% examples, 457793 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:16,651 : INFO : EPOCH 3 - PROGRESS: at 40.56% examples, 457599 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:17,668 : INFO : EPOCH 3 - PROGRESS: at 44.33% examples, 458160 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:18,684 : INFO : EPOCH 3 - PROGRESS: at 48.09% examples, 458842 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:19,686 : INFO : EPOCH 3 - PROGRESS: at 51.91% examples, 460143 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:20,696 : INFO : EPOCH 3 - PROGRESS: at 55.61% examples, 460345 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:21,702 : INFO : EPOCH 3 - PROGRESS: at 59.38% examples, 460848 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:22,705 : INFO : EPOCH 3 - PROGRESS: at 63.08% examples, 460946 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:23,723 : INFO : EPOCH 3 - PROGRESS: at 66.90% examples, 461447 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:24,732 : INFO : EPOCH 3 - PROGRESS: at 70.61% examples, 461444 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:25,738 : INFO : EPOCH 3 - PROGRESS: at 74.31% examples, 461529 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:26,746 : INFO : EPOCH 3 - PROGRESS: at 78.25% examples, 461979 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:27,757 : INFO : EPOCH 3 - PROGRESS: at 81.95% examples, 461720 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:28,777 : INFO : EPOCH 3 - PROGRESS: at 85.71% examples, 461736 words/s, in_qsize 5, out_qsize 0\n",
            "2018-11-03 20:42:29,780 : INFO : EPOCH 3 - PROGRESS: at 89.42% examples, 461733 words/s, in_qsize 4, out_qsize 1\n",
            "2018-11-03 20:42:30,783 : INFO : EPOCH 3 - PROGRESS: at 93.12% examples, 461653 words/s, in_qsize 6, out_qsize 2\n",
            "2018-11-03 20:42:31,796 : INFO : EPOCH 3 - PROGRESS: at 96.88% examples, 461671 words/s, in_qsize 5, out_qsize 1\n",
            "2018-11-03 20:42:32,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-03 20:42:32,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-03 20:42:32,609 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-03 20:42:32,610 : INFO : EPOCH - 3 : training on 17005207 raw words (12506606 effective words) took 27.1s, 462044 effective words/s\n",
            "2018-11-03 20:42:32,612 : INFO : training on a 51015621 raw words (37514496 effective words) took 81.0s, 463024 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37514496, 51015621)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "ifyLsuUQXdWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "76b1ce9d-783a-4d59-c3ab-2ef129d60520"
      },
      "cell_type": "code",
      "source": [
        "# Training is done and we can play a bit around\n",
        "\n",
        "# ask the model for most similar word to some term\n",
        "model_text8.wv.most_similar(\"milk\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 20:43:18,152 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('meat', 0.9049235582351685),\n",
              " ('fruit', 0.904716432094574),\n",
              " ('honey', 0.8918293714523315),\n",
              " ('beans', 0.8837248086929321),\n",
              " ('sugar', 0.8805627822875977),\n",
              " ('vegetables', 0.8805302381515503),\n",
              " ('beef', 0.8631115555763245),\n",
              " ('vegetable', 0.8613918423652649),\n",
              " ('drinks', 0.8598768711090088),\n",
              " ('chocolate', 0.8590322732925415)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "X5wYqOJ_VolR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b6989cf6-a289-48e3-db5a-2d091e77c117"
      },
      "cell_type": "code",
      "source": [
        "# Do some algebra exercises\n",
        "\n",
        "model_text8.wv.most_similar(positive=['germany', 'paris'], negative=['france'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('berlin', 0.8118886351585388),\n",
              " ('vienna', 0.7582015991210938),\n",
              " ('munich', 0.7417254447937012),\n",
              " ('moscow', 0.665905237197876),\n",
              " ('leipzig', 0.6623905897140503),\n",
              " ('milan', 0.6177572011947632),\n",
              " ('hamburg', 0.6133787631988525),\n",
              " ('frankfurt', 0.6034635305404663),\n",
              " ('bologna', 0.5932918190956116),\n",
              " ('bonn', 0.5911003351211548)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "nXuKixFIUf2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1cee60cb-9363-4850-9933-ebd6eda7d98b"
      },
      "cell_type": "code",
      "source": [
        "model_text8.wv.most_similar(positive=['japan', 'mercedes'], negative=['germany'])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('honda', 0.7667422294616699),\n",
              " ('sony', 0.7596989870071411),\n",
              " ('jeep', 0.7313293814659119),\n",
              " ('toyota', 0.7283535003662109),\n",
              " ('nintendo', 0.7144696712493896),\n",
              " ('mitsubishi', 0.7099435329437256),\n",
              " ('bmw', 0.7031159996986389),\n",
              " ('mazda', 0.6964906454086304),\n",
              " ('jaguar', 0.6929983496665955),\n",
              " ('motorcycle', 0.6928412914276123)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "T9XqFJyDrXCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "dc8ccaf3-3194-4623-bae9-5788a7124eb2"
      },
      "cell_type": "code",
      "source": [
        "# and more\n",
        "\n",
        "print(model_text8.wv.doesnt_match(['dog','cat','chicken','hamster']))\n",
        "print()\n",
        "print(model_text8.wv.doesnt_match(['bus','street','honey','house']))\n",
        "print()\n",
        "print(model_text8.wv.doesnt_match(['gin','vodka','beer','whiskey']))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chicken\n",
            "\n",
            "honey\n",
            "\n",
            "beer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fqltZz07VTOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Word2Vec on a specific copus (form memory)\n",
        "\n",
        "In the following we will train the model first on the toxic-comments data from [this Kaggle challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) \n",
        "\n",
        "Then, we will re-train the model with more data (yes, that's possible, since the Word2Vec model is actually a shallow neural network). Here we will use the hate-speech classification tweets"
      ]
    },
    {
      "metadata": {
        "id": "7uEBNblVYDOL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load up the toxic comments data\n",
        "\n",
        "toxic1 = pd.read_csv('train.csv')\n",
        "toxic2 = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVz4s4F2lkCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load up the hatespeech tweets\n",
        "\n",
        "hatespeech_tweets = pd.read_csv('labeled_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wuvyQjCzXLo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### some light preprocessing\n",
        "\n",
        "we will use twitter-style preprocessing to get rid of typical online-text issues."
      ]
    },
    {
      "metadata": {
        "id": "nkUGqUIFYQTJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import tweet-tokenizer\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxH9KZTEXX6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocess the toxic comments text\n",
        "# just tokenizing, loweing and removing everything that is not a word\n",
        "# given 2 files, we are doing it 2 times\n",
        "\n",
        "toxic1['tokenized'] = toxic1['comment_text'].map(lambda t: tknzr.tokenize(t))\n",
        "toxic1['tokenized'] = toxic1['tokenized'].map(lambda t: [x.lower() for x in t if x.isalpha()])\n",
        "\n",
        "toxic2['tokenized'] = toxic2['comment_text'].map(lambda t: tknzr.tokenize(t))\n",
        "toxic2['tokenized'] = toxic2['tokenized'].map(lambda t: [x.lower() for x in t if x.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4giQAuAuXsGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Finally, we can just concatenate the tokenized colum of both dataframes as out training data input\n",
        "\n",
        "toxic_data = pd.concat([toxic1['tokenized'],toxic2['tokenized']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTWfkk85mRqL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Same preprocessing for the hatespeech tweets.\n",
        "\n",
        "hatespeech_tweets['tokenized'] = hatespeech_tweets['tweet'].map(lambda t: tknzr.tokenize(t))\n",
        "hatespeech_tweets['tokenized'] = hatespeech_tweets['tokenized'].map(lambda t: [x.strip('#') for x in t])\n",
        "hatespeech_tweets['tokenized'] = hatespeech_tweets['tokenized'].map(lambda t: [x.lower() for x in t if x.isalpha()])\n",
        "hatespeech_tweets['tokenized'] = hatespeech_tweets['tokenized'].map(lambda t: [x for x in t if x !='rt'])\n",
        "\n",
        "### DONE ####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8n3NtuNctg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's bring all of the training data together\n",
        "all_hate_data = pd.concat([toxic_data, hatespeech_tweets['tokenized']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q07BgOdwkW_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Bonus material: Identification og bi-grams & co:"
      ]
    },
    {
      "metadata": {
        "id": "OMlb4gxHdepy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RalAhD5XdyXv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b4ab0e7e-a9e2-4ab6-e46f-4781dd4414a2"
      },
      "cell_type": "code",
      "source": [
        "phrases = Phrases(all_hate_data, min_count=5, threshold=10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-07 09:25:38,028 : INFO : collecting all words and their counts\n",
            "2018-11-07 09:25:38,049 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "2018-11-07 09:25:39,616 : INFO : PROGRESS: at sentence #10000, processed 655155 words and 285005 word types\n",
            "2018-11-07 09:25:41,238 : INFO : PROGRESS: at sentence #20000, processed 1297718 words and 477817 word types\n",
            "2018-11-07 09:25:42,844 : INFO : PROGRESS: at sentence #30000, processed 1928609 words and 642497 word types\n",
            "2018-11-07 09:25:44,497 : INFO : PROGRESS: at sentence #40000, processed 2584346 words and 800472 word types\n",
            "2018-11-07 09:25:46,018 : INFO : PROGRESS: at sentence #50000, processed 3219612 words and 941861 word types\n",
            "2018-11-07 09:25:47,617 : INFO : PROGRESS: at sentence #60000, processed 3887527 words and 1080208 word types\n",
            "2018-11-07 09:25:49,179 : INFO : PROGRESS: at sentence #70000, processed 4534434 words and 1210177 word types\n",
            "2018-11-07 09:25:50,752 : INFO : PROGRESS: at sentence #80000, processed 5180185 words and 1334794 word types\n",
            "2018-11-07 09:25:52,442 : INFO : PROGRESS: at sentence #90000, processed 5808163 words and 1451652 word types\n",
            "2018-11-07 09:25:53,981 : INFO : PROGRESS: at sentence #100000, processed 6446667 words and 1565608 word types\n",
            "2018-11-07 09:25:55,557 : INFO : PROGRESS: at sentence #110000, processed 7104669 words and 1680201 word types\n",
            "2018-11-07 09:25:57,065 : INFO : PROGRESS: at sentence #120000, processed 7727707 words and 1787197 word types\n",
            "2018-11-07 09:25:58,612 : INFO : PROGRESS: at sentence #130000, processed 8366226 words and 1890841 word types\n",
            "2018-11-07 09:26:00,186 : INFO : PROGRESS: at sentence #140000, processed 9013610 words and 1993938 word types\n",
            "2018-11-07 09:26:01,761 : INFO : PROGRESS: at sentence #150000, processed 9662740 words and 2094542 word types\n",
            "2018-11-07 09:26:03,321 : INFO : PROGRESS: at sentence #160000, processed 10300877 words and 2193991 word types\n",
            "2018-11-07 09:26:04,773 : INFO : PROGRESS: at sentence #170000, processed 10890470 words and 2305609 word types\n",
            "2018-11-07 09:26:06,230 : INFO : PROGRESS: at sentence #180000, processed 11476476 words and 2419913 word types\n",
            "2018-11-07 09:26:07,657 : INFO : PROGRESS: at sentence #190000, processed 12058283 words and 2524579 word types\n",
            "2018-11-07 09:26:09,107 : INFO : PROGRESS: at sentence #200000, processed 12641348 words and 2631948 word types\n",
            "2018-11-07 09:26:10,523 : INFO : PROGRESS: at sentence #210000, processed 13214148 words and 2734098 word types\n",
            "2018-11-07 09:26:12,301 : INFO : PROGRESS: at sentence #220000, processed 13801021 words and 2838091 word types\n",
            "2018-11-07 09:26:13,755 : INFO : PROGRESS: at sentence #230000, processed 14386389 words and 2943270 word types\n",
            "2018-11-07 09:26:15,214 : INFO : PROGRESS: at sentence #240000, processed 14970014 words and 3052544 word types\n",
            "2018-11-07 09:26:16,657 : INFO : PROGRESS: at sentence #250000, processed 15552888 words and 3150680 word types\n",
            "2018-11-07 09:26:18,084 : INFO : PROGRESS: at sentence #260000, processed 16128355 words and 3245689 word types\n",
            "2018-11-07 09:26:19,511 : INFO : PROGRESS: at sentence #270000, processed 16705792 words and 3339685 word types\n",
            "2018-11-07 09:26:20,967 : INFO : PROGRESS: at sentence #280000, processed 17294130 words and 3441893 word types\n",
            "2018-11-07 09:26:22,422 : INFO : PROGRESS: at sentence #290000, processed 17875512 words and 3536997 word types\n",
            "2018-11-07 09:26:23,875 : INFO : PROGRESS: at sentence #300000, processed 18445270 words and 3629074 word types\n",
            "2018-11-07 09:26:25,351 : INFO : PROGRESS: at sentence #310000, processed 19041697 words and 3726103 word types\n",
            "2018-11-07 09:26:25,983 : INFO : PROGRESS: at sentence #320000, processed 19290865 words and 3774645 word types\n",
            "2018-11-07 09:26:26,325 : INFO : PROGRESS: at sentence #330000, processed 19418735 words and 3805123 word types\n",
            "2018-11-07 09:26:26,576 : INFO : collected 3825076 word types from a corpus of 19511330 words (unigram + bigrams) and 337518 sentences\n",
            "2018-11-07 09:26:26,578 : INFO : using 3825076 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VWEwA_TXepQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be36789d-8d36-4a76-ef05-fda550fb3ef5"
      },
      "cell_type": "code",
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-07 09:27:34,632 : INFO : source_vocab length 3825076\n",
            "2018-11-07 09:28:22,622 : INFO : Phraser built with 27006 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9LhjyB98erbP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_hate_data_phrases = all_hate_data.map(lambda t: bigram[t])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9_bsADDqfAhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hatespeech_tweets['tokenized_phrases'] = hatespeech_tweets['tokenized'].map(lambda t: bigram[t])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOs6i9ONfNxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "1b527320-928f-42cb-d6bc-7a0b7c1cf698"
      },
      "cell_type": "code",
      "source": [
        "hatespeech_tweets['tokenized_phrases']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [as, a, woman, you, complain_about, cleaning_u...\n",
              "1        [boy, dats, cold, tyga, dwn, bad, for, cuffin,...\n",
              "2        [dawg, you, ever, fuck, a, bitch, and, she, st...\n",
              "3                             [she, look, like, a, tranny]\n",
              "4        [the, shit, you, hear, about, me, might, be, t...\n",
              "5        [the, shit, just, blows, me, claim, you, so, f...\n",
              "6        [i, can, not, just, sit, up, and, hate, on, an...\n",
              "7        [cause, tired, of, you, big, bitches, coming, ...\n",
              "8        [you, might, not, get, ya, bitch, back, thats,...\n",
              "9              [hobbies, include, fighting, mariam, bitch]\n",
              "10       [keeks, is, a, bitch, she, curves, everyone, l...\n",
              "11                   [murda, gang, bitch, its, gang, land]\n",
              "12       [so, hoes, that, smoke, are, losers, yea, go, ...\n",
              "13       [bad_bitches, is, the, only, thing, that, i, l...\n",
              "14                               [bitch, get, up, off, me]\n",
              "15                      [bitch, nigga, miss, me, with, it]\n",
              "16                                  [bitch, plz, whatever]\n",
              "17                             [bitch, who, do, you, love]\n",
              "18                    [bitches, get, cut_off, everyday, b]\n",
              "19                          [black, bottle, a, bad, bitch]\n",
              "20                  [broke, bitch, cant, tell_me, nothing]\n",
              "21                       [cancel, that, bitch, like, nino]\n",
              "22              [cant, you, see, these_hoes, wont, change]\n",
              "23       [fuck, no, that, bitch, dont, even, suck_dick,...\n",
              "24       [got, ya, bitch, tip, toeing, on, my, hardwood...\n",
              "25                  [her, pussy_lips, like, heaven, doors]\n",
              "26                          [hoe, what, its, hitting, for]\n",
              "27       [i, met, that, pussy, on, ocean, dr, i, gave, ...\n",
              "28       [i, need, a, trippy, bitch, who, fuck, on, hen...\n",
              "29       [i, spend, my, money, how, i, want, bitch, its...\n",
              "                               ...                        \n",
              "24753            [you, gotta, be, a, dyke, to, like, hoes]\n",
              "24754                      [you, are, a, hoe, hoe, a, hoe]\n",
              "24755        [you, bitches_love, yall, some, corny, nigga]\n",
              "24756    [you, can, masturbate, anytime, bitch, lol, i,...\n",
              "24757    [you, can, never, get, a, group, of, hoes, tog...\n",
              "24758    [you, can, tell, when, dick, recently, been, i...\n",
              "24759                            [you, cuff, a, hoe, lmao]\n",
              "24760                     [you, drove, me, redneck, crazy]\n",
              "24761                           [you, fake, niggah, lolol]\n",
              "24762             [you, got, niggas, and, i, got, bitches]\n",
              "24763    [you, gotta, be, a, new, breed, of, retarded, ...\n",
              "24764    [you, gotta, understand, that, these_bitches, ...\n",
              "24765                                    [you, hoe, spice]\n",
              "24766              [you, just, want, some, attention, hoe]\n",
              "24767    [you, know, what, they, say, the, early_bird, ...\n",
              "24768    [you, know, what, your, doing, when, you, favo...\n",
              "24769    [you, lil, dumb_ass, bitch, i, fuckin_wit, chu...\n",
              "24770    [you, look, like, ac, green, bitch, call, here...\n",
              "24771    [you, look, like, your, stop, talking_about, f...\n",
              "24772    [you, might, as, well, gone, pussy, pop, on, a...\n",
              "24773                   [you, niggers, cheat, on, ya, smh]\n",
              "24774    [you, really_care, bout, dis_bitch, my, dick, ...\n",
              "24775    [you, worried_bout, other, bitches, you, need,...\n",
              "24776                                       [all, niggers]\n",
              "24777    [such, a, retard, i, hope, you, get, type, dia...\n",
              "24778    [a, muthaf, in, lie, right, his, tl, is, trash...\n",
              "24779    [gone, and, broke, the, wrong, heart, baby, an...\n",
              "24780    [young_buck, wanna, eat, dat, nigguh, like, i,...\n",
              "24781        [youu, got, wild, bitches, tellin, you, lies]\n",
              "24782    [ruffled, ntac, eileen, dahlia, beautiful, col...\n",
              "Name: tokenized_phrases, Length: 24783, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "OcGpxuVpYi-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model training in one line\n",
        "\n",
        "We can actually instantiate, build vocabulary and train in one line only. Isn't that great?"
      ]
    },
    {
      "metadata": {
        "id": "5eSBBgKpZUeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2448
        },
        "outputId": "73dca9df-4f2a-4ba8-ad59-5c1ca6986ba1"
      },
      "cell_type": "code",
      "source": [
        "# We can instantiate and train the model in one line. Just pass the input data (sequence of token-lists)\n",
        "# specify target dimensionality (size), the window adound the target term, minimum count, and number of iterations/epochs\n",
        "# workers are optional (for multiprocessing)\n",
        "\n",
        "model_toxic = Word2Vec(toxic_data, size=100, window=5, min_count=5, workers=4, iter=3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-04 21:53:52,371 : INFO : collecting all words and their counts\n",
            "2018-11-04 21:53:52,496 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-11-04 21:53:52,677 : INFO : PROGRESS: at sentence #10000, processed 655155 words, keeping 33301 word types\n",
            "2018-11-04 21:53:52,863 : INFO : PROGRESS: at sentence #20000, processed 1297718 words, keeping 49193 word types\n",
            "2018-11-04 21:53:53,049 : INFO : PROGRESS: at sentence #30000, processed 1928609 words, keeping 61707 word types\n",
            "2018-11-04 21:53:53,241 : INFO : PROGRESS: at sentence #40000, processed 2584346 words, keeping 72823 word types\n",
            "2018-11-04 21:53:53,426 : INFO : PROGRESS: at sentence #50000, processed 3219612 words, keeping 82595 word types\n",
            "2018-11-04 21:53:53,622 : INFO : PROGRESS: at sentence #60000, processed 3887527 words, keeping 91889 word types\n",
            "2018-11-04 21:53:53,816 : INFO : PROGRESS: at sentence #70000, processed 4534434 words, keeping 100497 word types\n",
            "2018-11-04 21:53:54,008 : INFO : PROGRESS: at sentence #80000, processed 5180185 words, keeping 108491 word types\n",
            "2018-11-04 21:53:54,195 : INFO : PROGRESS: at sentence #90000, processed 5808163 words, keeping 115793 word types\n",
            "2018-11-04 21:53:54,384 : INFO : PROGRESS: at sentence #100000, processed 6446667 words, keeping 122921 word types\n",
            "2018-11-04 21:53:54,581 : INFO : PROGRESS: at sentence #110000, processed 7104669 words, keeping 129843 word types\n",
            "2018-11-04 21:53:54,770 : INFO : PROGRESS: at sentence #120000, processed 7727707 words, keeping 136425 word types\n",
            "2018-11-04 21:53:54,964 : INFO : PROGRESS: at sentence #130000, processed 8366226 words, keeping 142670 word types\n",
            "2018-11-04 21:53:55,163 : INFO : PROGRESS: at sentence #140000, processed 9013610 words, keeping 149016 word types\n",
            "2018-11-04 21:53:55,373 : INFO : PROGRESS: at sentence #150000, processed 9662740 words, keeping 155180 word types\n",
            "2018-11-04 21:53:55,573 : INFO : PROGRESS: at sentence #160000, processed 10300877 words, keeping 161216 word types\n",
            "2018-11-04 21:53:55,867 : INFO : PROGRESS: at sentence #170000, processed 10890470 words, keeping 172480 word types\n",
            "2018-11-04 21:53:56,143 : INFO : PROGRESS: at sentence #180000, processed 11476476 words, keeping 183846 word types\n",
            "2018-11-04 21:53:56,328 : INFO : PROGRESS: at sentence #190000, processed 12058283 words, keeping 193102 word types\n",
            "2018-11-04 21:53:56,519 : INFO : PROGRESS: at sentence #200000, processed 12641348 words, keeping 203033 word types\n",
            "2018-11-04 21:53:56,700 : INFO : PROGRESS: at sentence #210000, processed 13214148 words, keeping 212858 word types\n",
            "2018-11-04 21:53:56,889 : INFO : PROGRESS: at sentence #220000, processed 13801021 words, keeping 221810 word types\n",
            "2018-11-04 21:53:57,079 : INFO : PROGRESS: at sentence #230000, processed 14386389 words, keeping 231411 word types\n",
            "2018-11-04 21:53:57,267 : INFO : PROGRESS: at sentence #240000, processed 14970014 words, keeping 242788 word types\n",
            "2018-11-04 21:53:57,454 : INFO : PROGRESS: at sentence #250000, processed 15552888 words, keeping 251686 word types\n",
            "2018-11-04 21:53:57,640 : INFO : PROGRESS: at sentence #260000, processed 16128355 words, keeping 259947 word types\n",
            "2018-11-04 21:53:57,826 : INFO : PROGRESS: at sentence #270000, processed 16705792 words, keeping 267681 word types\n",
            "2018-11-04 21:53:58,023 : INFO : PROGRESS: at sentence #280000, processed 17294130 words, keeping 277016 word types\n",
            "2018-11-04 21:53:58,211 : INFO : PROGRESS: at sentence #290000, processed 17875512 words, keeping 284992 word types\n",
            "2018-11-04 21:53:58,398 : INFO : PROGRESS: at sentence #300000, processed 18445270 words, keeping 292731 word types\n",
            "2018-11-04 21:53:58,589 : INFO : PROGRESS: at sentence #310000, processed 19041697 words, keeping 301325 word types\n",
            "2018-11-04 21:53:58,654 : INFO : collected 303684 word types from a corpus of 19210184 raw words and 312735 sentences\n",
            "2018-11-04 21:53:58,655 : INFO : Loading a fresh vocabulary\n",
            "2018-11-04 21:53:58,967 : INFO : effective_min_count=5 retains 62352 unique words (20% of original 303684, drops 241332)\n",
            "2018-11-04 21:53:58,968 : INFO : effective_min_count=5 leaves 18856477 word corpus (98% of original 19210184, drops 353707)\n",
            "2018-11-04 21:53:59,174 : INFO : deleting the raw counts dictionary of 303684 items\n",
            "2018-11-04 21:53:59,184 : INFO : sample=0.001 downsamples 51 most-common words\n",
            "2018-11-04 21:53:59,186 : INFO : downsampling leaves estimated 14286417 word corpus (75.8% of prior 18856477)\n",
            "2018-11-04 21:53:59,499 : INFO : estimated required memory for 62352 words and 100 dimensions: 81057600 bytes\n",
            "2018-11-04 21:53:59,500 : INFO : resetting layer weights\n",
            "2018-11-04 21:54:00,154 : INFO : training model with 4 workers on 62352 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-11-04 21:54:01,188 : INFO : EPOCH 1 - PROGRESS: at 3.24% examples, 486115 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:02,196 : INFO : EPOCH 1 - PROGRESS: at 6.53% examples, 487733 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:03,205 : INFO : EPOCH 1 - PROGRESS: at 9.89% examples, 487944 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:04,222 : INFO : EPOCH 1 - PROGRESS: at 13.09% examples, 485619 words/s, in_qsize 5, out_qsize 2\n",
            "2018-11-04 21:54:05,243 : INFO : EPOCH 1 - PROGRESS: at 16.46% examples, 486451 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:06,255 : INFO : EPOCH 1 - PROGRESS: at 19.73% examples, 489073 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:07,260 : INFO : EPOCH 1 - PROGRESS: at 23.02% examples, 489077 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:08,268 : INFO : EPOCH 1 - PROGRESS: at 26.23% examples, 487164 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:09,298 : INFO : EPOCH 1 - PROGRESS: at 29.65% examples, 487734 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:10,311 : INFO : EPOCH 1 - PROGRESS: at 33.03% examples, 488397 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:11,347 : INFO : EPOCH 1 - PROGRESS: at 36.39% examples, 488368 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:12,361 : INFO : EPOCH 1 - PROGRESS: at 39.87% examples, 489402 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:13,405 : INFO : EPOCH 1 - PROGRESS: at 43.27% examples, 489088 words/s, in_qsize 5, out_qsize 2\n",
            "2018-11-04 21:54:14,434 : INFO : EPOCH 1 - PROGRESS: at 46.65% examples, 489366 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:15,443 : INFO : EPOCH 1 - PROGRESS: at 50.03% examples, 490241 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:16,456 : INFO : EPOCH 1 - PROGRESS: at 53.64% examples, 490963 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:17,468 : INFO : EPOCH 1 - PROGRESS: at 57.31% examples, 491150 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 21:54:18,475 : INFO : EPOCH 1 - PROGRESS: at 60.93% examples, 491124 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:19,500 : INFO : EPOCH 1 - PROGRESS: at 64.75% examples, 491280 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:20,505 : INFO : EPOCH 1 - PROGRESS: at 68.31% examples, 491231 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:21,516 : INFO : EPOCH 1 - PROGRESS: at 72.01% examples, 491419 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:22,520 : INFO : EPOCH 1 - PROGRESS: at 75.59% examples, 491012 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 21:54:23,545 : INFO : EPOCH 1 - PROGRESS: at 79.31% examples, 491261 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:24,566 : INFO : EPOCH 1 - PROGRESS: at 83.03% examples, 490934 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:25,578 : INFO : EPOCH 1 - PROGRESS: at 86.81% examples, 491454 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:26,608 : INFO : EPOCH 1 - PROGRESS: at 90.45% examples, 491175 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:27,610 : INFO : EPOCH 1 - PROGRESS: at 94.10% examples, 491218 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:28,622 : INFO : EPOCH 1 - PROGRESS: at 97.75% examples, 491089 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:29,217 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 21:54:29,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 21:54:29,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 21:54:29,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 21:54:29,245 : INFO : EPOCH - 1 : training on 19210184 raw words (14286048 effective words) took 29.1s, 491433 effective words/s\n",
            "2018-11-04 21:54:30,266 : INFO : EPOCH 2 - PROGRESS: at 3.19% examples, 483678 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 21:54:31,292 : INFO : EPOCH 2 - PROGRESS: at 6.64% examples, 493142 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:32,296 : INFO : EPOCH 2 - PROGRESS: at 10.08% examples, 497258 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:33,299 : INFO : EPOCH 2 - PROGRESS: at 13.28% examples, 494180 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:34,341 : INFO : EPOCH 2 - PROGRESS: at 16.73% examples, 494109 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:35,352 : INFO : EPOCH 2 - PROGRESS: at 19.96% examples, 494521 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:36,374 : INFO : EPOCH 2 - PROGRESS: at 23.36% examples, 494651 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:37,407 : INFO : EPOCH 2 - PROGRESS: at 26.73% examples, 493134 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 21:54:38,412 : INFO : EPOCH 2 - PROGRESS: at 30.07% examples, 492855 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:39,445 : INFO : EPOCH 2 - PROGRESS: at 33.41% examples, 492003 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:40,462 : INFO : EPOCH 2 - PROGRESS: at 36.76% examples, 491911 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:41,481 : INFO : EPOCH 2 - PROGRESS: at 40.17% examples, 491870 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:42,492 : INFO : EPOCH 2 - PROGRESS: at 43.61% examples, 493131 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:43,505 : INFO : EPOCH 2 - PROGRESS: at 46.98% examples, 493714 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:44,543 : INFO : EPOCH 2 - PROGRESS: at 50.33% examples, 492831 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:45,562 : INFO : EPOCH 2 - PROGRESS: at 53.89% examples, 492777 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:46,563 : INFO : EPOCH 2 - PROGRESS: at 57.46% examples, 492298 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:47,575 : INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 492104 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:48,582 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 491903 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:49,612 : INFO : EPOCH 2 - PROGRESS: at 68.52% examples, 492324 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:50,615 : INFO : EPOCH 2 - PROGRESS: at 72.16% examples, 492312 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:51,617 : INFO : EPOCH 2 - PROGRESS: at 75.86% examples, 492561 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 21:54:52,651 : INFO : EPOCH 2 - PROGRESS: at 79.47% examples, 491902 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:53,669 : INFO : EPOCH 2 - PROGRESS: at 83.25% examples, 491899 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:54,673 : INFO : EPOCH 2 - PROGRESS: at 86.98% examples, 492221 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:55,704 : INFO : EPOCH 2 - PROGRESS: at 90.63% examples, 491892 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:54:56,706 : INFO : EPOCH 2 - PROGRESS: at 94.27% examples, 491948 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:57,708 : INFO : EPOCH 2 - PROGRESS: at 97.81% examples, 491463 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:54:58,294 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 21:54:58,301 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 21:54:58,311 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 21:54:58,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 21:54:58,325 : INFO : EPOCH - 2 : training on 19210184 raw words (14287204 effective words) took 29.1s, 491641 effective words/s\n",
            "2018-11-04 21:54:59,375 : INFO : EPOCH 3 - PROGRESS: at 3.27% examples, 486258 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:00,390 : INFO : EPOCH 3 - PROGRESS: at 6.59% examples, 486102 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:01,398 : INFO : EPOCH 3 - PROGRESS: at 9.99% examples, 489459 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:02,422 : INFO : EPOCH 3 - PROGRESS: at 13.28% examples, 491499 words/s, in_qsize 7, out_qsize 2\n",
            "2018-11-04 21:55:03,420 : INFO : EPOCH 3 - PROGRESS: at 16.55% examples, 488942 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:55:04,426 : INFO : EPOCH 3 - PROGRESS: at 19.59% examples, 485745 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 21:55:05,454 : INFO : EPOCH 3 - PROGRESS: at 22.97% examples, 486610 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:06,456 : INFO : EPOCH 3 - PROGRESS: at 26.37% examples, 489013 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:07,478 : INFO : EPOCH 3 - PROGRESS: at 29.61% examples, 486599 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:08,479 : INFO : EPOCH 3 - PROGRESS: at 32.88% examples, 486522 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:09,490 : INFO : EPOCH 3 - PROGRESS: at 36.22% examples, 487698 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:10,498 : INFO : EPOCH 3 - PROGRESS: at 39.62% examples, 487867 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:11,498 : INFO : EPOCH 3 - PROGRESS: at 42.94% examples, 488151 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:12,511 : INFO : EPOCH 3 - PROGRESS: at 46.24% examples, 488563 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 21:55:13,516 : INFO : EPOCH 3 - PROGRESS: at 49.59% examples, 489073 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:14,521 : INFO : EPOCH 3 - PROGRESS: at 53.04% examples, 489163 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:15,533 : INFO : EPOCH 3 - PROGRESS: at 56.66% examples, 489093 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:16,533 : INFO : EPOCH 3 - PROGRESS: at 60.31% examples, 489371 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:17,574 : INFO : EPOCH 3 - PROGRESS: at 64.03% examples, 489252 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:18,574 : INFO : EPOCH 3 - PROGRESS: at 67.78% examples, 490115 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:19,576 : INFO : EPOCH 3 - PROGRESS: at 71.37% examples, 489907 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:20,582 : INFO : EPOCH 3 - PROGRESS: at 75.05% examples, 490248 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 21:55:21,600 : INFO : EPOCH 3 - PROGRESS: at 78.78% examples, 490639 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:22,617 : INFO : EPOCH 3 - PROGRESS: at 82.54% examples, 490707 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:23,635 : INFO : EPOCH 3 - PROGRESS: at 86.20% examples, 490705 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:24,636 : INFO : EPOCH 3 - PROGRESS: at 89.90% examples, 491084 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:25,641 : INFO : EPOCH 3 - PROGRESS: at 93.53% examples, 490856 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:26,666 : INFO : EPOCH 3 - PROGRESS: at 97.14% examples, 490196 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 21:55:27,434 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 21:55:27,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 21:55:27,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 21:55:27,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 21:55:27,469 : INFO : EPOCH - 3 : training on 19210184 raw words (14287451 effective words) took 29.1s, 490588 effective words/s\n",
            "2018-11-04 21:55:27,470 : INFO : training on a 57630552 raw words (42860703 effective words) took 87.3s, 490873 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-Qs7pT8ZqIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "21631617-aa99-4268-ff5c-fdef534b605e"
      },
      "cell_type": "code",
      "source": [
        "# Does it work? The output of this cell makes it clear: Yes, it works pretty well.\n",
        "\n",
        "model_toxic.wv.most_similar('idiot')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 21:06:12,882 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('asshole', 0.8236082196235657),\n",
              " ('moron', 0.7038889527320862),\n",
              " ('imbecile', 0.6953639388084412),\n",
              " ('fool', 0.6788172721862793),\n",
              " ('loser', 0.6326109170913696),\n",
              " ('illiterate', 0.6308602094650269),\n",
              " ('ignorant', 0.6303929090499878),\n",
              " ('hypocrite', 0.6218823194503784),\n",
              " ('retard', 0.6214895248413086),\n",
              " ('insult', 0.6125708818435669)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "dCwnRH6SZ3Cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "56e07e94-dd0e-4be9-f806-ff9626a8988d"
      },
      "cell_type": "code",
      "source": [
        "# something less violent?\n",
        "\n",
        "model_toxic.wv.most_similar('mother')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('father', 0.8239043354988098),\n",
              " ('wife', 0.8019334077835083),\n",
              " ('grandmother', 0.7894612550735474),\n",
              " ('mom', 0.7853889465332031),\n",
              " ('sister', 0.7848141193389893),\n",
              " ('dad', 0.7723446488380432),\n",
              " ('tongue', 0.7573986649513245),\n",
              " ('daughter', 0.7491512298583984),\n",
              " ('boyfriend', 0.745460033416748),\n",
              " ('parents', 0.7441803812980652)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "ze3r1ABfZ5M6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1c244c4d-5dca-4e2b-f0b8-c42ebfd75585"
      },
      "cell_type": "code",
      "source": [
        "model_toxic.save('model.m')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 21:08:23,499 : INFO : saving Word2Vec object under model.m, separately None\n",
            "2018-11-03 21:08:23,501 : INFO : not storing attribute vectors_norm\n",
            "2018-11-03 21:08:23,504 : INFO : not storing attribute cum_table\n",
            "2018-11-03 21:08:24,328 : INFO : saved model.m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xWjYZ9JLZqQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now imagine, you trained a model and would like to update it with new data later. \n",
        "\n",
        "You can save your model for later re-use just like that:\n",
        "\n",
        "```\n",
        "model_toxic.save('model.m')\n",
        "```\n",
        "\n",
        "To re-train, we need to \n",
        "- build some additional vocab (perhaps the new data contains some new words)\n",
        "- train the model using the ```train``` method. (surprise)\n"
      ]
    },
    {
      "metadata": {
        "id": "ZTuvyxiGu_3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "dada2af4-98fd-449e-ba9d-1c314985b50b"
      },
      "cell_type": "code",
      "source": [
        "# Build ne vocab from new data, telling the model that it's an update\n",
        "\n",
        "model_toxic.build_vocab(hatespeech_tweets['tokenized'], update=True)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 21:11:09,890 : INFO : collecting all words and their counts\n",
            "2018-11-03 21:11:09,893 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-11-03 21:11:09,927 : INFO : PROGRESS: at sentence #10000, processed 111788 words, keeping 10979 word types\n",
            "2018-11-03 21:11:09,968 : INFO : PROGRESS: at sentence #20000, processed 247332 words, keeping 16372 word types\n",
            "2018-11-03 21:11:09,986 : INFO : collected 18336 word types from a corpus of 305428 raw words and 24783 sentences\n",
            "2018-11-03 21:11:09,988 : INFO : Updating model with new vocabulary\n",
            "2018-11-03 21:11:10,007 : INFO : New added 4191 unique words (18% of original 22527) and increased the count of 4191 pre-existing words (18% of original 22527)\n",
            "2018-11-03 21:11:10,038 : INFO : deleting the raw counts dictionary of 18336 items\n",
            "2018-11-03 21:11:10,040 : INFO : sample=0.001 downsamples 124 most-common words\n",
            "2018-11-03 21:11:10,041 : INFO : downsampling leaves estimated 408334 word corpus (144.1% of prior 283362)\n",
            "2018-11-03 21:11:10,218 : INFO : estimated required memory for 8382 words and 100 dimensions: 10896600 bytes\n",
            "2018-11-03 21:11:10,219 : INFO : updating layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "r1GyQ10z52S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d7cc1ae8-9971-44fb-ef28-66367a989dab"
      },
      "cell_type": "code",
      "source": [
        "# Re-train (you need to specify total_examples) \n",
        "# we only have ~25k tweets...and it shouldnt take long\n",
        "\n",
        "model_toxic.train(hatespeech_tweets['tokenized'], total_examples = model_toxic.corpus_count, epochs=2)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 21:12:38,380 : WARNING : Effective 'alpha' higher than previous training cycles\n",
            "2018-11-03 21:12:38,382 : INFO : training model with 4 workers on 62589 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-11-03 21:12:38,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-03 21:12:38,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-03 21:12:38,808 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-03 21:12:38,815 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-03 21:12:38,816 : INFO : EPOCH - 1 : training on 305428 raw words (219843 effective words) took 0.4s, 524751 effective words/s\n",
            "2018-11-03 21:12:39,207 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-03 21:12:39,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-03 21:12:39,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-03 21:12:39,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-03 21:12:39,228 : INFO : EPOCH - 2 : training on 305428 raw words (219816 effective words) took 0.4s, 556892 effective words/s\n",
            "2018-11-03 21:12:39,229 : INFO : training on a 610856 raw words (439659 effective words) took 0.8s, 519834 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(439659, 610856)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "dT8a5VwpbIdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "16842b04-e561-44b4-b97d-35da5a28542e"
      },
      "cell_type": "code",
      "source": [
        "# Any new linguistic insights\n",
        "\n",
        "model_toxic.wv.most_similar('idiot')\n",
        "\n",
        "# Some of the words changed place but other than that...no big changes"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-03 21:13:46,429 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('asshole', 0.8278401494026184),\n",
              " ('moron', 0.7025822401046753),\n",
              " ('imbecile', 0.7006790637969971),\n",
              " ('fool', 0.6777839660644531),\n",
              " ('illiterate', 0.6400813460350037),\n",
              " ('loser', 0.6324371099472046),\n",
              " ('ignorant', 0.6284880042076111),\n",
              " ('retard', 0.628136396408081),\n",
              " ('hypocrite', 0.6253594756126404),\n",
              " ('insult', 0.6170707941055298)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "wUAl-DzlfiSQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Finally, we can train a fastText model (thanks Facebook for that)\n",
        "\n",
        "This will be ~4 times slower than Word2Vec (since the algo has to account for all the sub-word-stuff etc.)"
      ]
    },
    {
      "metadata": {
        "id": "MhHc3STmc_FX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11764
        },
        "outputId": "7e32e0ae-120e-4867-b8c7-ef7df639dada"
      },
      "cell_type": "code",
      "source": [
        "model_toxic_fasttext = FastText(all_hate_data, size=100, window=8, min_count=3, workers=4, iter=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-04 20:13:37,648 : INFO : collecting all words and their counts\n",
            "2018-11-04 20:13:37,669 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-11-04 20:13:37,827 : INFO : PROGRESS: at sentence #10000, processed 655155 words, keeping 33301 word types\n",
            "2018-11-04 20:13:38,002 : INFO : PROGRESS: at sentence #20000, processed 1297718 words, keeping 49193 word types\n",
            "2018-11-04 20:13:38,171 : INFO : PROGRESS: at sentence #30000, processed 1928609 words, keeping 61707 word types\n",
            "2018-11-04 20:13:38,355 : INFO : PROGRESS: at sentence #40000, processed 2584346 words, keeping 72823 word types\n",
            "2018-11-04 20:13:38,537 : INFO : PROGRESS: at sentence #50000, processed 3219612 words, keeping 82595 word types\n",
            "2018-11-04 20:13:38,730 : INFO : PROGRESS: at sentence #60000, processed 3887527 words, keeping 91889 word types\n",
            "2018-11-04 20:13:38,915 : INFO : PROGRESS: at sentence #70000, processed 4534434 words, keeping 100497 word types\n",
            "2018-11-04 20:13:39,098 : INFO : PROGRESS: at sentence #80000, processed 5180185 words, keeping 108491 word types\n",
            "2018-11-04 20:13:39,272 : INFO : PROGRESS: at sentence #90000, processed 5808163 words, keeping 115793 word types\n",
            "2018-11-04 20:13:39,454 : INFO : PROGRESS: at sentence #100000, processed 6446667 words, keeping 122921 word types\n",
            "2018-11-04 20:13:39,639 : INFO : PROGRESS: at sentence #110000, processed 7104669 words, keeping 129843 word types\n",
            "2018-11-04 20:13:39,818 : INFO : PROGRESS: at sentence #120000, processed 7727707 words, keeping 136425 word types\n",
            "2018-11-04 20:13:39,996 : INFO : PROGRESS: at sentence #130000, processed 8366226 words, keeping 142670 word types\n",
            "2018-11-04 20:13:40,173 : INFO : PROGRESS: at sentence #140000, processed 9013610 words, keeping 149016 word types\n",
            "2018-11-04 20:13:40,350 : INFO : PROGRESS: at sentence #150000, processed 9662740 words, keeping 155180 word types\n",
            "2018-11-04 20:13:40,526 : INFO : PROGRESS: at sentence #160000, processed 10300877 words, keeping 161216 word types\n",
            "2018-11-04 20:13:40,687 : INFO : PROGRESS: at sentence #170000, processed 10890470 words, keeping 172480 word types\n",
            "2018-11-04 20:13:40,871 : INFO : PROGRESS: at sentence #180000, processed 11476476 words, keeping 183846 word types\n",
            "2018-11-04 20:13:41,042 : INFO : PROGRESS: at sentence #190000, processed 12058283 words, keeping 193102 word types\n",
            "2018-11-04 20:13:41,207 : INFO : PROGRESS: at sentence #200000, processed 12641348 words, keeping 203033 word types\n",
            "2018-11-04 20:13:41,375 : INFO : PROGRESS: at sentence #210000, processed 13214148 words, keeping 212858 word types\n",
            "2018-11-04 20:13:41,543 : INFO : PROGRESS: at sentence #220000, processed 13801021 words, keeping 221810 word types\n",
            "2018-11-04 20:13:41,709 : INFO : PROGRESS: at sentence #230000, processed 14386389 words, keeping 231411 word types\n",
            "2018-11-04 20:13:41,885 : INFO : PROGRESS: at sentence #240000, processed 14970014 words, keeping 242788 word types\n",
            "2018-11-04 20:13:42,054 : INFO : PROGRESS: at sentence #250000, processed 15552888 words, keeping 251686 word types\n",
            "2018-11-04 20:13:42,217 : INFO : PROGRESS: at sentence #260000, processed 16128355 words, keeping 259947 word types\n",
            "2018-11-04 20:13:42,382 : INFO : PROGRESS: at sentence #270000, processed 16705792 words, keeping 267681 word types\n",
            "2018-11-04 20:13:42,551 : INFO : PROGRESS: at sentence #280000, processed 17294130 words, keeping 277016 word types\n",
            "2018-11-04 20:13:42,723 : INFO : PROGRESS: at sentence #290000, processed 17875512 words, keeping 284992 word types\n",
            "2018-11-04 20:13:42,889 : INFO : PROGRESS: at sentence #300000, processed 18445270 words, keeping 292731 word types\n",
            "2018-11-04 20:13:43,072 : INFO : PROGRESS: at sentence #310000, processed 19041697 words, keeping 301325 word types\n",
            "2018-11-04 20:13:43,155 : INFO : PROGRESS: at sentence #320000, processed 19289845 words, keeping 304708 word types\n",
            "2018-11-04 20:13:43,202 : INFO : PROGRESS: at sentence #330000, processed 19420220 words, keeping 306010 word types\n",
            "2018-11-04 20:13:43,239 : INFO : collected 306828 word types from a corpus of 19515612 raw words and 337518 sentences\n",
            "2018-11-04 20:13:43,241 : INFO : Loading a fresh vocabulary\n",
            "2018-11-04 20:13:44,232 : INFO : effective_min_count=3 retains 93210 unique words (30% of original 306828, drops 213618)\n",
            "2018-11-04 20:13:44,233 : INFO : effective_min_count=3 leaves 19260231 word corpus (98% of original 19515612, drops 255381)\n",
            "2018-11-04 20:13:44,526 : INFO : deleting the raw counts dictionary of 306828 items\n",
            "2018-11-04 20:13:44,537 : INFO : sample=0.001 downsamples 51 most-common words\n",
            "2018-11-04 20:13:44,540 : INFO : downsampling leaves estimated 14654611 word corpus (76.1% of prior 19260231)\n",
            "2018-11-04 20:13:46,466 : INFO : estimated required memory for 93210 words, 411589 buckets and 100 dimensions: 307118768 bytes\n",
            "2018-11-04 20:13:46,490 : INFO : resetting layer weights\n",
            "2018-11-04 20:13:50,552 : INFO : Total number of ngrams is 411589\n",
            "2018-11-04 20:13:53,813 : INFO : training model with 4 workers on 93210 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=8\n",
            "2018-11-04 20:13:54,932 : INFO : EPOCH 1 - PROGRESS: at 0.65% examples, 94377 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:13:55,973 : INFO : EPOCH 1 - PROGRESS: at 1.36% examples, 103829 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:13:57,043 : INFO : EPOCH 1 - PROGRESS: at 2.07% examples, 106137 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:13:58,089 : INFO : EPOCH 1 - PROGRESS: at 2.77% examples, 107774 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:13:59,093 : INFO : EPOCH 1 - PROGRESS: at 3.42% examples, 108251 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:00,172 : INFO : EPOCH 1 - PROGRESS: at 4.15% examples, 108590 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:01,234 : INFO : EPOCH 1 - PROGRESS: at 4.89% examples, 108969 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:02,299 : INFO : EPOCH 1 - PROGRESS: at 5.62% examples, 109369 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:03,387 : INFO : EPOCH 1 - PROGRESS: at 6.39% examples, 109320 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:04,445 : INFO : EPOCH 1 - PROGRESS: at 7.15% examples, 109750 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:05,523 : INFO : EPOCH 1 - PROGRESS: at 7.90% examples, 109560 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:06,586 : INFO : EPOCH 1 - PROGRESS: at 8.61% examples, 109726 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:07,709 : INFO : EPOCH 1 - PROGRESS: at 9.34% examples, 109418 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:08,837 : INFO : EPOCH 1 - PROGRESS: at 10.04% examples, 109101 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:14:09,927 : INFO : EPOCH 1 - PROGRESS: at 10.75% examples, 109092 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:10,943 : INFO : EPOCH 1 - PROGRESS: at 11.44% examples, 109129 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:11,970 : INFO : EPOCH 1 - PROGRESS: at 12.09% examples, 108686 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:13,055 : INFO : EPOCH 1 - PROGRESS: at 12.76% examples, 108344 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:14,170 : INFO : EPOCH 1 - PROGRESS: at 13.54% examples, 108200 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:15,194 : INFO : EPOCH 1 - PROGRESS: at 14.22% examples, 108246 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:16,266 : INFO : EPOCH 1 - PROGRESS: at 14.90% examples, 108096 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:17,247 : INFO : EPOCH 1 - PROGRESS: at 15.50% examples, 107902 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:18,292 : INFO : EPOCH 1 - PROGRESS: at 16.15% examples, 107818 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:19,330 : INFO : EPOCH 1 - PROGRESS: at 16.81% examples, 107822 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:20,398 : INFO : EPOCH 1 - PROGRESS: at 17.53% examples, 107968 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:21,455 : INFO : EPOCH 1 - PROGRESS: at 18.11% examples, 107329 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:22,571 : INFO : EPOCH 1 - PROGRESS: at 18.79% examples, 107299 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:23,733 : INFO : EPOCH 1 - PROGRESS: at 19.51% examples, 107157 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:14:24,786 : INFO : EPOCH 1 - PROGRESS: at 20.29% examples, 107455 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:25,818 : INFO : EPOCH 1 - PROGRESS: at 21.00% examples, 107549 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:26,814 : INFO : EPOCH 1 - PROGRESS: at 21.70% examples, 107599 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:27,847 : INFO : EPOCH 1 - PROGRESS: at 22.38% examples, 107595 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:28,894 : INFO : EPOCH 1 - PROGRESS: at 23.04% examples, 107555 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:29,979 : INFO : EPOCH 1 - PROGRESS: at 23.77% examples, 107596 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:14:31,028 : INFO : EPOCH 1 - PROGRESS: at 24.52% examples, 107735 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:32,067 : INFO : EPOCH 1 - PROGRESS: at 25.32% examples, 108093 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:33,071 : INFO : EPOCH 1 - PROGRESS: at 26.06% examples, 108366 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:34,077 : INFO : EPOCH 1 - PROGRESS: at 26.67% examples, 108038 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:35,155 : INFO : EPOCH 1 - PROGRESS: at 27.39% examples, 108083 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:36,205 : INFO : EPOCH 1 - PROGRESS: at 28.13% examples, 108208 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:37,277 : INFO : EPOCH 1 - PROGRESS: at 28.87% examples, 108284 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:38,318 : INFO : EPOCH 1 - PROGRESS: at 29.61% examples, 108413 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:39,409 : INFO : EPOCH 1 - PROGRESS: at 30.33% examples, 108410 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:40,463 : INFO : EPOCH 1 - PROGRESS: at 31.05% examples, 108494 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:41,497 : INFO : EPOCH 1 - PROGRESS: at 31.71% examples, 108487 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:14:42,511 : INFO : EPOCH 1 - PROGRESS: at 32.42% examples, 108647 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:43,512 : INFO : EPOCH 1 - PROGRESS: at 33.04% examples, 108549 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:44,553 : INFO : EPOCH 1 - PROGRESS: at 33.81% examples, 108686 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:45,620 : INFO : EPOCH 1 - PROGRESS: at 34.58% examples, 108689 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:46,695 : INFO : EPOCH 1 - PROGRESS: at 35.31% examples, 108726 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:14:47,769 : INFO : EPOCH 1 - PROGRESS: at 36.06% examples, 108771 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:48,886 : INFO : EPOCH 1 - PROGRESS: at 36.85% examples, 108853 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:49,910 : INFO : EPOCH 1 - PROGRESS: at 37.59% examples, 108983 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:50,978 : INFO : EPOCH 1 - PROGRESS: at 38.32% examples, 109013 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:52,043 : INFO : EPOCH 1 - PROGRESS: at 39.03% examples, 109055 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:14:53,100 : INFO : EPOCH 1 - PROGRESS: at 39.79% examples, 109091 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:54,182 : INFO : EPOCH 1 - PROGRESS: at 40.51% examples, 109098 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:55,269 : INFO : EPOCH 1 - PROGRESS: at 41.20% examples, 109091 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:56,328 : INFO : EPOCH 1 - PROGRESS: at 41.95% examples, 109142 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:57,362 : INFO : EPOCH 1 - PROGRESS: at 42.67% examples, 109231 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:58,382 : INFO : EPOCH 1 - PROGRESS: at 43.35% examples, 109226 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:14:59,449 : INFO : EPOCH 1 - PROGRESS: at 44.07% examples, 109252 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:00,550 : INFO : EPOCH 1 - PROGRESS: at 44.78% examples, 109259 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:15:01,614 : INFO : EPOCH 1 - PROGRESS: at 45.52% examples, 109254 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:02,761 : INFO : EPOCH 1 - PROGRESS: at 46.31% examples, 109266 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:03,832 : INFO : EPOCH 1 - PROGRESS: at 47.05% examples, 109289 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:04,902 : INFO : EPOCH 1 - PROGRESS: at 47.78% examples, 109318 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:15:05,965 : INFO : EPOCH 1 - PROGRESS: at 48.64% examples, 109455 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:06,972 : INFO : EPOCH 1 - PROGRESS: at 49.39% examples, 109481 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:08,016 : INFO : EPOCH 1 - PROGRESS: at 50.18% examples, 109539 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:09,018 : INFO : EPOCH 1 - PROGRESS: at 50.92% examples, 109576 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:15:10,074 : INFO : EPOCH 1 - PROGRESS: at 51.71% examples, 109607 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:11,110 : INFO : EPOCH 1 - PROGRESS: at 52.55% examples, 109676 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:12,164 : INFO : EPOCH 1 - PROGRESS: at 53.34% examples, 109712 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:13,218 : INFO : EPOCH 1 - PROGRESS: at 54.18% examples, 109757 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:14,268 : INFO : EPOCH 1 - PROGRESS: at 55.01% examples, 109805 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:15,310 : INFO : EPOCH 1 - PROGRESS: at 55.79% examples, 109870 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:16,370 : INFO : EPOCH 1 - PROGRESS: at 56.57% examples, 109891 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:17,435 : INFO : EPOCH 1 - PROGRESS: at 57.38% examples, 109917 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:18,487 : INFO : EPOCH 1 - PROGRESS: at 58.19% examples, 109951 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:15:19,576 : INFO : EPOCH 1 - PROGRESS: at 59.01% examples, 110014 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:20,587 : INFO : EPOCH 1 - PROGRESS: at 59.89% examples, 110098 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:21,657 : INFO : EPOCH 1 - PROGRESS: at 60.71% examples, 110205 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:22,720 : INFO : EPOCH 1 - PROGRESS: at 61.54% examples, 110221 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:23,791 : INFO : EPOCH 1 - PROGRESS: at 62.34% examples, 110255 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:24,778 : INFO : EPOCH 1 - PROGRESS: at 63.03% examples, 110254 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:25,859 : INFO : EPOCH 1 - PROGRESS: at 63.84% examples, 110259 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:26,932 : INFO : EPOCH 1 - PROGRESS: at 64.67% examples, 110260 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:27,974 : INFO : EPOCH 1 - PROGRESS: at 65.49% examples, 110305 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:28,998 : INFO : EPOCH 1 - PROGRESS: at 66.30% examples, 110372 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:30,029 : INFO : EPOCH 1 - PROGRESS: at 67.06% examples, 110421 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:31,095 : INFO : EPOCH 1 - PROGRESS: at 67.80% examples, 110356 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:32,135 : INFO : EPOCH 1 - PROGRESS: at 68.67% examples, 110400 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:33,190 : INFO : EPOCH 1 - PROGRESS: at 69.45% examples, 110426 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:34,295 : INFO : EPOCH 1 - PROGRESS: at 70.30% examples, 110459 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:35,349 : INFO : EPOCH 1 - PROGRESS: at 71.10% examples, 110493 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:36,397 : INFO : EPOCH 1 - PROGRESS: at 71.91% examples, 110528 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:37,497 : INFO : EPOCH 1 - PROGRESS: at 72.69% examples, 110522 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:38,529 : INFO : EPOCH 1 - PROGRESS: at 73.48% examples, 110541 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:39,535 : INFO : EPOCH 1 - PROGRESS: at 74.28% examples, 110544 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:15:40,660 : INFO : EPOCH 1 - PROGRESS: at 75.15% examples, 110561 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:41,690 : INFO : EPOCH 1 - PROGRESS: at 75.98% examples, 110604 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:42,737 : INFO : EPOCH 1 - PROGRESS: at 76.83% examples, 110707 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:43,798 : INFO : EPOCH 1 - PROGRESS: at 77.66% examples, 110724 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:44,884 : INFO : EPOCH 1 - PROGRESS: at 78.55% examples, 110789 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:45,892 : INFO : EPOCH 1 - PROGRESS: at 79.27% examples, 110783 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:46,936 : INFO : EPOCH 1 - PROGRESS: at 80.08% examples, 110812 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:47,940 : INFO : EPOCH 1 - PROGRESS: at 80.91% examples, 110878 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:48,991 : INFO : EPOCH 1 - PROGRESS: at 81.69% examples, 110903 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:50,058 : INFO : EPOCH 1 - PROGRESS: at 82.49% examples, 110922 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:51,053 : INFO : EPOCH 1 - PROGRESS: at 83.16% examples, 110848 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:52,100 : INFO : EPOCH 1 - PROGRESS: at 83.98% examples, 110889 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:53,086 : INFO : EPOCH 1 - PROGRESS: at 84.72% examples, 110892 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:54,204 : INFO : EPOCH 1 - PROGRESS: at 85.60% examples, 110915 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:55,263 : INFO : EPOCH 1 - PROGRESS: at 86.38% examples, 110930 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:56,266 : INFO : EPOCH 1 - PROGRESS: at 87.14% examples, 110926 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:57,279 : INFO : EPOCH 1 - PROGRESS: at 87.95% examples, 110917 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:15:58,312 : INFO : EPOCH 1 - PROGRESS: at 88.76% examples, 110955 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:15:59,383 : INFO : EPOCH 1 - PROGRESS: at 89.56% examples, 110948 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:00,478 : INFO : EPOCH 1 - PROGRESS: at 90.34% examples, 110927 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:01,560 : INFO : EPOCH 1 - PROGRESS: at 91.18% examples, 110992 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:02,633 : INFO : EPOCH 1 - PROGRESS: at 91.98% examples, 110993 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:03,640 : INFO : EPOCH 1 - PROGRESS: at 93.05% examples, 111070 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:04,686 : INFO : EPOCH 1 - PROGRESS: at 98.11% examples, 111483 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:04,977 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 20:16:05,008 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 20:16:05,015 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 20:16:05,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 20:16:05,039 : INFO : EPOCH - 1 : training on 19515612 raw words (14652801 effective words) took 131.2s, 111677 effective words/s\n",
            "2018-11-04 20:16:06,089 : INFO : EPOCH 2 - PROGRESS: at 0.59% examples, 93623 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:07,149 : INFO : EPOCH 2 - PROGRESS: at 1.32% examples, 103021 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:08,159 : INFO : EPOCH 2 - PROGRESS: at 1.96% examples, 105250 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:09,262 : INFO : EPOCH 2 - PROGRESS: at 2.73% examples, 107523 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:16:10,362 : INFO : EPOCH 2 - PROGRESS: at 3.46% examples, 108820 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:11,374 : INFO : EPOCH 2 - PROGRESS: at 4.20% examples, 110242 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:12,427 : INFO : EPOCH 2 - PROGRESS: at 4.85% examples, 108821 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:16:13,417 : INFO : EPOCH 2 - PROGRESS: at 5.58% examples, 110006 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:14,429 : INFO : EPOCH 2 - PROGRESS: at 6.30% examples, 109981 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:16:15,526 : INFO : EPOCH 2 - PROGRESS: at 7.05% examples, 109713 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:16,565 : INFO : EPOCH 2 - PROGRESS: at 7.81% examples, 110112 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:17,615 : INFO : EPOCH 2 - PROGRESS: at 8.51% examples, 110299 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:18,690 : INFO : EPOCH 2 - PROGRESS: at 9.25% examples, 110341 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:19,775 : INFO : EPOCH 2 - PROGRESS: at 9.95% examples, 110275 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:16:20,933 : INFO : EPOCH 2 - PROGRESS: at 10.70% examples, 110301 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:21,982 : INFO : EPOCH 2 - PROGRESS: at 11.44% examples, 110510 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:22,972 : INFO : EPOCH 2 - PROGRESS: at 12.17% examples, 110927 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:23,992 : INFO : EPOCH 2 - PROGRESS: at 12.82% examples, 110447 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:16:25,110 : INFO : EPOCH 2 - PROGRESS: at 13.63% examples, 110549 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:26,119 : INFO : EPOCH 2 - PROGRESS: at 14.31% examples, 110543 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:27,181 : INFO : EPOCH 2 - PROGRESS: at 14.98% examples, 110244 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:16:28,192 : INFO : EPOCH 2 - PROGRESS: at 15.67% examples, 110518 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:29,206 : INFO : EPOCH 2 - PROGRESS: at 16.33% examples, 110468 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:30,235 : INFO : EPOCH 2 - PROGRESS: at 16.94% examples, 110107 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:31,299 : INFO : EPOCH 2 - PROGRESS: at 17.66% examples, 110165 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:32,380 : INFO : EPOCH 2 - PROGRESS: at 18.36% examples, 110176 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:16:33,514 : INFO : EPOCH 2 - PROGRESS: at 19.11% examples, 110196 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:34,556 : INFO : EPOCH 2 - PROGRESS: at 19.81% examples, 110287 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:16:35,591 : INFO : EPOCH 2 - PROGRESS: at 20.60% examples, 110419 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:36,622 : INFO : EPOCH 2 - PROGRESS: at 21.28% examples, 110332 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:37,666 : INFO : EPOCH 2 - PROGRESS: at 22.00% examples, 110290 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:38,775 : INFO : EPOCH 2 - PROGRESS: at 22.70% examples, 110127 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:39,783 : INFO : EPOCH 2 - PROGRESS: at 23.42% examples, 110328 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:40,860 : INFO : EPOCH 2 - PROGRESS: at 24.16% examples, 110295 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:16:41,861 : INFO : EPOCH 2 - PROGRESS: at 24.85% examples, 110318 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:16:42,932 : INFO : EPOCH 2 - PROGRESS: at 25.59% examples, 110326 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:44,011 : INFO : EPOCH 2 - PROGRESS: at 26.33% examples, 110324 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:45,097 : INFO : EPOCH 2 - PROGRESS: at 27.07% examples, 110276 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:46,147 : INFO : EPOCH 2 - PROGRESS: at 27.81% examples, 110349 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:47,235 : INFO : EPOCH 2 - PROGRESS: at 28.53% examples, 110322 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:48,309 : INFO : EPOCH 2 - PROGRESS: at 29.30% examples, 110373 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:49,315 : INFO : EPOCH 2 - PROGRESS: at 29.97% examples, 110328 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:16:50,385 : INFO : EPOCH 2 - PROGRESS: at 30.70% examples, 110342 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:51,449 : INFO : EPOCH 2 - PROGRESS: at 31.39% examples, 110398 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:52,435 : INFO : EPOCH 2 - PROGRESS: at 32.07% examples, 110408 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:53,493 : INFO : EPOCH 2 - PROGRESS: at 32.77% examples, 110437 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:54,497 : INFO : EPOCH 2 - PROGRESS: at 33.45% examples, 110429 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:55,546 : INFO : EPOCH 2 - PROGRESS: at 34.20% examples, 110333 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:16:56,633 : INFO : EPOCH 2 - PROGRESS: at 34.95% examples, 110301 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:57,722 : INFO : EPOCH 2 - PROGRESS: at 35.70% examples, 110283 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:58,755 : INFO : EPOCH 2 - PROGRESS: at 36.48% examples, 110506 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:16:59,806 : INFO : EPOCH 2 - PROGRESS: at 37.13% examples, 110281 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:00,882 : INFO : EPOCH 2 - PROGRESS: at 37.86% examples, 110277 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:02,008 : INFO : EPOCH 2 - PROGRESS: at 38.59% examples, 110177 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:03,088 : INFO : EPOCH 2 - PROGRESS: at 39.33% examples, 110162 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:04,142 : INFO : EPOCH 2 - PROGRESS: at 40.04% examples, 110184 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:05,236 : INFO : EPOCH 2 - PROGRESS: at 40.75% examples, 110146 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:06,340 : INFO : EPOCH 2 - PROGRESS: at 41.53% examples, 110210 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:07,421 : INFO : EPOCH 2 - PROGRESS: at 42.27% examples, 110209 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:08,493 : INFO : EPOCH 2 - PROGRESS: at 42.97% examples, 110217 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:09,585 : INFO : EPOCH 2 - PROGRESS: at 43.74% examples, 110184 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:10,595 : INFO : EPOCH 2 - PROGRESS: at 44.42% examples, 110282 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:11,664 : INFO : EPOCH 2 - PROGRESS: at 45.14% examples, 110285 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:12,751 : INFO : EPOCH 2 - PROGRESS: at 45.90% examples, 110267 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:13,816 : INFO : EPOCH 2 - PROGRESS: at 46.64% examples, 110280 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:14,872 : INFO : EPOCH 2 - PROGRESS: at 47.36% examples, 110314 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:15,987 : INFO : EPOCH 2 - PROGRESS: at 48.19% examples, 110361 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:17,041 : INFO : EPOCH 2 - PROGRESS: at 48.99% examples, 110391 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:18,118 : INFO : EPOCH 2 - PROGRESS: at 49.79% examples, 110407 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:17:19,162 : INFO : EPOCH 2 - PROGRESS: at 50.60% examples, 110450 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:20,182 : INFO : EPOCH 2 - PROGRESS: at 51.38% examples, 110568 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:21,274 : INFO : EPOCH 2 - PROGRESS: at 52.22% examples, 110605 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:22,290 : INFO : EPOCH 2 - PROGRESS: at 53.06% examples, 110684 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:23,331 : INFO : EPOCH 2 - PROGRESS: at 53.82% examples, 110639 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:24,337 : INFO : EPOCH 2 - PROGRESS: at 54.60% examples, 110647 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:25,416 : INFO : EPOCH 2 - PROGRESS: at 55.39% examples, 110648 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:26,450 : INFO : EPOCH 2 - PROGRESS: at 56.17% examples, 110705 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:27,521 : INFO : EPOCH 2 - PROGRESS: at 56.97% examples, 110715 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:28,585 : INFO : EPOCH 2 - PROGRESS: at 57.79% examples, 110727 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:29,642 : INFO : EPOCH 2 - PROGRESS: at 58.59% examples, 110741 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:30,667 : INFO : EPOCH 2 - PROGRESS: at 59.39% examples, 110795 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:31,680 : INFO : EPOCH 2 - PROGRESS: at 60.19% examples, 110782 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:32,695 : INFO : EPOCH 2 - PROGRESS: at 60.92% examples, 110777 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:33,723 : INFO : EPOCH 2 - PROGRESS: at 61.75% examples, 110828 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:34,802 : INFO : EPOCH 2 - PROGRESS: at 62.52% examples, 110812 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:35,826 : INFO : EPOCH 2 - PROGRESS: at 63.30% examples, 110874 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:36,880 : INFO : EPOCH 2 - PROGRESS: at 64.06% examples, 110819 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:37,941 : INFO : EPOCH 2 - PROGRESS: at 64.86% examples, 110829 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:38,976 : INFO : EPOCH 2 - PROGRESS: at 65.68% examples, 110876 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:40,032 : INFO : EPOCH 2 - PROGRESS: at 66.49% examples, 110932 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:41,016 : INFO : EPOCH 2 - PROGRESS: at 67.21% examples, 110923 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:42,045 : INFO : EPOCH 2 - PROGRESS: at 67.96% examples, 110898 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:43,087 : INFO : EPOCH 2 - PROGRESS: at 68.82% examples, 110931 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:17:44,190 : INFO : EPOCH 2 - PROGRESS: at 69.63% examples, 110990 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:45,203 : INFO : EPOCH 2 - PROGRESS: at 70.40% examples, 110956 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:17:46,233 : INFO : EPOCH 2 - PROGRESS: at 71.21% examples, 111012 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:47,292 : INFO : EPOCH 2 - PROGRESS: at 72.02% examples, 111030 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:48,331 : INFO : EPOCH 2 - PROGRESS: at 72.79% examples, 111066 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:49,386 : INFO : EPOCH 2 - PROGRESS: at 73.59% examples, 111074 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:50,463 : INFO : EPOCH 2 - PROGRESS: at 74.44% examples, 111076 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:51,535 : INFO : EPOCH 2 - PROGRESS: at 75.24% examples, 111069 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:17:52,568 : INFO : EPOCH 2 - PROGRESS: at 76.06% examples, 111105 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:53,650 : INFO : EPOCH 2 - PROGRESS: at 76.87% examples, 111099 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:17:54,713 : INFO : EPOCH 2 - PROGRESS: at 77.71% examples, 111111 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:55,795 : INFO : EPOCH 2 - PROGRESS: at 78.55% examples, 111106 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:56,904 : INFO : EPOCH 2 - PROGRESS: at 79.36% examples, 111127 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:57,946 : INFO : EPOCH 2 - PROGRESS: at 80.19% examples, 111158 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:58,967 : INFO : EPOCH 2 - PROGRESS: at 80.95% examples, 111141 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:17:59,978 : INFO : EPOCH 2 - PROGRESS: at 81.73% examples, 111201 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:01,008 : INFO : EPOCH 2 - PROGRESS: at 82.52% examples, 111246 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:02,003 : INFO : EPOCH 2 - PROGRESS: at 83.25% examples, 111237 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:03,073 : INFO : EPOCH 2 - PROGRESS: at 84.02% examples, 111170 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:04,078 : INFO : EPOCH 2 - PROGRESS: at 84.77% examples, 111174 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:05,157 : INFO : EPOCH 2 - PROGRESS: at 85.61% examples, 111167 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:06,184 : INFO : EPOCH 2 - PROGRESS: at 86.35% examples, 111168 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:07,224 : INFO : EPOCH 2 - PROGRESS: at 87.14% examples, 111190 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:08,210 : INFO : EPOCH 2 - PROGRESS: at 87.95% examples, 111187 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:09,270 : INFO : EPOCH 2 - PROGRESS: at 88.78% examples, 111201 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:10,274 : INFO : EPOCH 2 - PROGRESS: at 89.56% examples, 111251 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:11,305 : INFO : EPOCH 2 - PROGRESS: at 90.29% examples, 111225 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:12,350 : INFO : EPOCH 2 - PROGRESS: at 91.07% examples, 111264 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:13,386 : INFO : EPOCH 2 - PROGRESS: at 91.82% examples, 111237 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:14,474 : INFO : EPOCH 2 - PROGRESS: at 92.60% examples, 111239 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:18:15,541 : INFO : EPOCH 2 - PROGRESS: at 97.25% examples, 111579 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:18:15,933 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 20:18:15,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 20:18:15,978 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 20:18:16,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 20:18:16,022 : INFO : EPOCH - 2 : training on 19515612 raw words (14654420 effective words) took 131.0s, 111900 effective words/s\n",
            "2018-11-04 20:18:17,105 : INFO : EPOCH 3 - PROGRESS: at 0.61% examples, 90775 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:18,198 : INFO : EPOCH 3 - PROGRESS: at 1.36% examples, 103312 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:19,241 : INFO : EPOCH 3 - PROGRESS: at 2.07% examples, 106556 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:20,368 : INFO : EPOCH 3 - PROGRESS: at 2.81% examples, 108114 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:18:21,412 : INFO : EPOCH 3 - PROGRESS: at 3.56% examples, 110241 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:22,474 : INFO : EPOCH 3 - PROGRESS: at 4.28% examples, 110498 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:23,485 : INFO : EPOCH 3 - PROGRESS: at 4.97% examples, 110437 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:24,493 : INFO : EPOCH 3 - PROGRESS: at 5.67% examples, 110459 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:25,564 : INFO : EPOCH 3 - PROGRESS: at 6.44% examples, 110502 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:26,655 : INFO : EPOCH 3 - PROGRESS: at 7.20% examples, 110277 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:18:27,707 : INFO : EPOCH 3 - PROGRESS: at 7.94% examples, 110454 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:28,784 : INFO : EPOCH 3 - PROGRESS: at 8.66% examples, 110427 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:29,788 : INFO : EPOCH 3 - PROGRESS: at 9.34% examples, 110476 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:30,865 : INFO : EPOCH 3 - PROGRESS: at 10.04% examples, 110455 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:18:31,898 : INFO : EPOCH 3 - PROGRESS: at 10.75% examples, 110756 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:32,916 : INFO : EPOCH 3 - PROGRESS: at 11.44% examples, 110685 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:33,930 : INFO : EPOCH 3 - PROGRESS: at 12.17% examples, 111060 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:34,932 : INFO : EPOCH 3 - PROGRESS: at 12.82% examples, 110676 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:35,945 : INFO : EPOCH 3 - PROGRESS: at 13.54% examples, 110595 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:37,076 : INFO : EPOCH 3 - PROGRESS: at 14.31% examples, 110677 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:38,128 : INFO : EPOCH 3 - PROGRESS: at 15.02% examples, 110752 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:39,165 : INFO : EPOCH 3 - PROGRESS: at 15.67% examples, 110713 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:18:40,184 : INFO : EPOCH 3 - PROGRESS: at 16.33% examples, 110499 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:41,309 : INFO : EPOCH 3 - PROGRESS: at 17.07% examples, 110592 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:42,356 : INFO : EPOCH 3 - PROGRESS: at 17.79% examples, 110709 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:43,422 : INFO : EPOCH 3 - PROGRESS: at 18.54% examples, 111025 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:44,430 : INFO : EPOCH 3 - PROGRESS: at 19.21% examples, 110972 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:45,466 : INFO : EPOCH 3 - PROGRESS: at 19.87% examples, 110813 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:18:46,477 : INFO : EPOCH 3 - PROGRESS: at 20.60% examples, 110776 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:47,594 : INFO : EPOCH 3 - PROGRESS: at 21.38% examples, 110847 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:48,672 : INFO : EPOCH 3 - PROGRESS: at 22.13% examples, 110827 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:49,823 : INFO : EPOCH 3 - PROGRESS: at 22.87% examples, 110779 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:50,882 : INFO : EPOCH 3 - PROGRESS: at 23.59% examples, 110811 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:51,956 : INFO : EPOCH 3 - PROGRESS: at 24.34% examples, 110782 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:53,100 : INFO : EPOCH 3 - PROGRESS: at 25.11% examples, 110744 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:54,124 : INFO : EPOCH 3 - PROGRESS: at 25.88% examples, 110886 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:55,198 : INFO : EPOCH 3 - PROGRESS: at 26.62% examples, 110918 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:56,285 : INFO : EPOCH 3 - PROGRESS: at 27.35% examples, 110863 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:57,344 : INFO : EPOCH 3 - PROGRESS: at 28.09% examples, 110849 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:58,407 : INFO : EPOCH 3 - PROGRESS: at 28.83% examples, 110881 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:18:59,464 : INFO : EPOCH 3 - PROGRESS: at 29.56% examples, 110920 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:19:00,467 : INFO : EPOCH 3 - PROGRESS: at 30.19% examples, 110741 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:19:01,505 : INFO : EPOCH 3 - PROGRESS: at 30.91% examples, 110818 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:02,511 : INFO : EPOCH 3 - PROGRESS: at 31.58% examples, 110806 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:03,578 : INFO : EPOCH 3 - PROGRESS: at 32.29% examples, 110818 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:04,780 : INFO : EPOCH 3 - PROGRESS: at 33.04% examples, 110658 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:19:05,830 : INFO : EPOCH 3 - PROGRESS: at 33.85% examples, 110851 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:06,917 : INFO : EPOCH 3 - PROGRESS: at 34.62% examples, 110804 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:19:07,985 : INFO : EPOCH 3 - PROGRESS: at 35.36% examples, 110813 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:08,994 : INFO : EPOCH 3 - PROGRESS: at 36.06% examples, 110812 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:10,066 : INFO : EPOCH 3 - PROGRESS: at 36.81% examples, 110806 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:11,177 : INFO : EPOCH 3 - PROGRESS: at 37.55% examples, 110722 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:12,192 : INFO : EPOCH 3 - PROGRESS: at 38.27% examples, 110825 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:13,260 : INFO : EPOCH 3 - PROGRESS: at 38.99% examples, 110826 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:14,326 : INFO : EPOCH 3 - PROGRESS: at 39.75% examples, 110853 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:19:15,353 : INFO : EPOCH 3 - PROGRESS: at 40.45% examples, 110897 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:16,417 : INFO : EPOCH 3 - PROGRESS: at 41.15% examples, 110894 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:17,468 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 110960 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:18,476 : INFO : EPOCH 3 - PROGRESS: at 42.59% examples, 110915 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:19,521 : INFO : EPOCH 3 - PROGRESS: at 43.27% examples, 110847 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:19:20,549 : INFO : EPOCH 3 - PROGRESS: at 43.91% examples, 110680 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:21,716 : INFO : EPOCH 3 - PROGRESS: at 44.59% examples, 110516 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:19:22,827 : INFO : EPOCH 3 - PROGRESS: at 45.38% examples, 110554 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:23,859 : INFO : EPOCH 3 - PROGRESS: at 46.05% examples, 110401 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:25,001 : INFO : EPOCH 3 - PROGRESS: at 46.77% examples, 110296 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:26,032 : INFO : EPOCH 3 - PROGRESS: at 47.46% examples, 110260 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:27,092 : INFO : EPOCH 3 - PROGRESS: at 48.14% examples, 110081 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:19:28,149 : INFO : EPOCH 3 - PROGRESS: at 48.94% examples, 110117 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:29,153 : INFO : EPOCH 3 - PROGRESS: at 49.70% examples, 110141 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:30,236 : INFO : EPOCH 3 - PROGRESS: at 50.40% examples, 109933 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:31,260 : INFO : EPOCH 3 - PROGRESS: at 51.16% examples, 110022 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:32,270 : INFO : EPOCH 3 - PROGRESS: at 51.87% examples, 109920 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:33,384 : INFO : EPOCH 3 - PROGRESS: at 52.65% examples, 109779 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:34,520 : INFO : EPOCH 3 - PROGRESS: at 53.44% examples, 109705 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:35,591 : INFO : EPOCH 3 - PROGRESS: at 54.30% examples, 109728 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:36,661 : INFO : EPOCH 3 - PROGRESS: at 55.10% examples, 109746 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:37,708 : INFO : EPOCH 3 - PROGRESS: at 55.88% examples, 109796 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:38,726 : INFO : EPOCH 3 - PROGRESS: at 56.68% examples, 109880 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:39,838 : INFO : EPOCH 3 - PROGRESS: at 57.48% examples, 109845 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:40,947 : INFO : EPOCH 3 - PROGRESS: at 58.32% examples, 109895 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:42,023 : INFO : EPOCH 3 - PROGRESS: at 59.17% examples, 109977 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:43,088 : INFO : EPOCH 3 - PROGRESS: at 60.04% examples, 110023 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:44,199 : INFO : EPOCH 3 - PROGRESS: at 60.88% examples, 110046 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:45,268 : INFO : EPOCH 3 - PROGRESS: at 61.70% examples, 110057 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:46,275 : INFO : EPOCH 3 - PROGRESS: at 62.47% examples, 110139 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:47,338 : INFO : EPOCH 3 - PROGRESS: at 63.19% examples, 110082 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:48,409 : INFO : EPOCH 3 - PROGRESS: at 64.06% examples, 110178 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:49,533 : INFO : EPOCH 3 - PROGRESS: at 64.92% examples, 110201 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:50,598 : INFO : EPOCH 3 - PROGRESS: at 65.73% examples, 110221 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:51,660 : INFO : EPOCH 3 - PROGRESS: at 66.54% examples, 110244 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:52,670 : INFO : EPOCH 3 - PROGRESS: at 67.31% examples, 110315 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:53,674 : INFO : EPOCH 3 - PROGRESS: at 68.09% examples, 110327 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:54,750 : INFO : EPOCH 3 - PROGRESS: at 68.92% examples, 110328 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:55,800 : INFO : EPOCH 3 - PROGRESS: at 69.68% examples, 110356 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:56,857 : INFO : EPOCH 3 - PROGRESS: at 70.51% examples, 110381 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:57,861 : INFO : EPOCH 3 - PROGRESS: at 71.26% examples, 110397 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:58,899 : INFO : EPOCH 3 - PROGRESS: at 72.07% examples, 110475 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:19:59,927 : INFO : EPOCH 3 - PROGRESS: at 72.79% examples, 110422 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:00,941 : INFO : EPOCH 3 - PROGRESS: at 73.54% examples, 110407 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:01,964 : INFO : EPOCH 3 - PROGRESS: at 74.33% examples, 110400 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:02,994 : INFO : EPOCH 3 - PROGRESS: at 75.19% examples, 110514 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:03,995 : INFO : EPOCH 3 - PROGRESS: at 75.93% examples, 110451 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:20:04,996 : INFO : EPOCH 3 - PROGRESS: at 76.73% examples, 110533 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:20:06,013 : INFO : EPOCH 3 - PROGRESS: at 77.45% examples, 110464 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:20:07,111 : INFO : EPOCH 3 - PROGRESS: at 78.34% examples, 110516 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:08,174 : INFO : EPOCH 3 - PROGRESS: at 79.13% examples, 110530 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:09,221 : INFO : EPOCH 3 - PROGRESS: at 79.92% examples, 110552 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:10,287 : INFO : EPOCH 3 - PROGRESS: at 80.75% examples, 110570 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:11,319 : INFO : EPOCH 3 - PROGRESS: at 81.55% examples, 110613 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:12,372 : INFO : EPOCH 3 - PROGRESS: at 82.40% examples, 110691 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:13,455 : INFO : EPOCH 3 - PROGRESS: at 83.16% examples, 110678 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:14,506 : INFO : EPOCH 3 - PROGRESS: at 83.98% examples, 110695 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:15,598 : INFO : EPOCH 3 - PROGRESS: at 84.77% examples, 110683 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:16,649 : INFO : EPOCH 3 - PROGRESS: at 85.61% examples, 110708 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:17,678 : INFO : EPOCH 3 - PROGRESS: at 86.38% examples, 110754 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:18,720 : INFO : EPOCH 3 - PROGRESS: at 87.19% examples, 110778 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:19,751 : INFO : EPOCH 3 - PROGRESS: at 88.05% examples, 110815 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:20,766 : INFO : EPOCH 3 - PROGRESS: at 88.82% examples, 110811 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:20:21,834 : INFO : EPOCH 3 - PROGRESS: at 89.61% examples, 110810 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:22,887 : INFO : EPOCH 3 - PROGRESS: at 90.39% examples, 110828 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:23,895 : INFO : EPOCH 3 - PROGRESS: at 91.18% examples, 110902 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:24,994 : INFO : EPOCH 3 - PROGRESS: at 91.98% examples, 110880 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:26,014 : INFO : EPOCH 3 - PROGRESS: at 93.03% examples, 110949 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:27,052 : INFO : EPOCH 3 - PROGRESS: at 97.68% examples, 111244 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:27,319 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 20:20:27,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 20:20:27,414 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 20:20:27,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 20:20:27,441 : INFO : EPOCH - 3 : training on 19515612 raw words (14655308 effective words) took 131.4s, 111534 effective words/s\n",
            "2018-11-04 20:20:28,544 : INFO : EPOCH 4 - PROGRESS: at 0.65% examples, 95790 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:29,611 : INFO : EPOCH 4 - PROGRESS: at 1.36% examples, 103430 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:30,642 : INFO : EPOCH 4 - PROGRESS: at 2.07% examples, 107190 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:31,774 : INFO : EPOCH 4 - PROGRESS: at 2.81% examples, 108226 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:20:32,839 : INFO : EPOCH 4 - PROGRESS: at 3.51% examples, 108684 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:20:33,909 : INFO : EPOCH 4 - PROGRESS: at 4.24% examples, 109114 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:34,967 : INFO : EPOCH 4 - PROGRESS: at 4.97% examples, 109568 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:36,034 : INFO : EPOCH 4 - PROGRESS: at 5.71% examples, 109866 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:37,047 : INFO : EPOCH 4 - PROGRESS: at 6.49% examples, 110610 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:38,068 : INFO : EPOCH 4 - PROGRESS: at 7.19% examples, 110395 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:39,168 : INFO : EPOCH 4 - PROGRESS: at 7.94% examples, 110110 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:40,234 : INFO : EPOCH 4 - PROGRESS: at 8.71% examples, 110787 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:41,276 : INFO : EPOCH 4 - PROGRESS: at 9.38% examples, 110494 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:42,302 : INFO : EPOCH 4 - PROGRESS: at 10.04% examples, 110353 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:20:43,336 : INFO : EPOCH 4 - PROGRESS: at 10.75% examples, 110646 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:44,411 : INFO : EPOCH 4 - PROGRESS: at 11.49% examples, 110660 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:45,462 : INFO : EPOCH 4 - PROGRESS: at 12.21% examples, 110806 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:46,555 : INFO : EPOCH 4 - PROGRESS: at 13.02% examples, 111068 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:47,628 : INFO : EPOCH 4 - PROGRESS: at 13.77% examples, 111027 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:48,817 : INFO : EPOCH 4 - PROGRESS: at 14.53% examples, 110750 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:49,843 : INFO : EPOCH 4 - PROGRESS: at 15.25% examples, 110951 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:50,906 : INFO : EPOCH 4 - PROGRESS: at 15.93% examples, 110960 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:51,996 : INFO : EPOCH 4 - PROGRESS: at 16.62% examples, 110881 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:53,151 : INFO : EPOCH 4 - PROGRESS: at 17.38% examples, 110825 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:54,224 : INFO : EPOCH 4 - PROGRESS: at 18.15% examples, 111086 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:55,269 : INFO : EPOCH 4 - PROGRESS: at 18.85% examples, 111188 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:56,299 : INFO : EPOCH 4 - PROGRESS: at 19.51% examples, 111061 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:57,305 : INFO : EPOCH 4 - PROGRESS: at 20.20% examples, 110995 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:20:58,333 : INFO : EPOCH 4 - PROGRESS: at 20.92% examples, 110906 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:20:59,403 : INFO : EPOCH 4 - PROGRESS: at 21.66% examples, 110913 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:00,434 : INFO : EPOCH 4 - PROGRESS: at 22.34% examples, 110814 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:01,524 : INFO : EPOCH 4 - PROGRESS: at 23.04% examples, 110749 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:02,613 : INFO : EPOCH 4 - PROGRESS: at 23.77% examples, 110684 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:03,685 : INFO : EPOCH 4 - PROGRESS: at 24.52% examples, 110662 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:21:04,786 : INFO : EPOCH 4 - PROGRESS: at 25.32% examples, 110759 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:05,817 : INFO : EPOCH 4 - PROGRESS: at 26.06% examples, 110895 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:06,849 : INFO : EPOCH 4 - PROGRESS: at 26.77% examples, 110784 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:07,934 : INFO : EPOCH 4 - PROGRESS: at 27.48% examples, 110747 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:09,018 : INFO : EPOCH 4 - PROGRESS: at 28.21% examples, 110720 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:10,081 : INFO : EPOCH 4 - PROGRESS: at 28.96% examples, 110749 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:11,150 : INFO : EPOCH 4 - PROGRESS: at 29.71% examples, 110761 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:12,208 : INFO : EPOCH 4 - PROGRESS: at 30.42% examples, 110780 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:21:13,260 : INFO : EPOCH 4 - PROGRESS: at 31.14% examples, 110866 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:14,293 : INFO : EPOCH 4 - PROGRESS: at 31.84% examples, 110917 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:15,331 : INFO : EPOCH 4 - PROGRESS: at 32.54% examples, 110978 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:16,369 : INFO : EPOCH 4 - PROGRESS: at 33.27% examples, 111041 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:17,385 : INFO : EPOCH 4 - PROGRESS: at 33.96% examples, 110860 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:18,394 : INFO : EPOCH 4 - PROGRESS: at 34.71% examples, 110986 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:19,438 : INFO : EPOCH 4 - PROGRESS: at 35.46% examples, 111039 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:20,602 : INFO : EPOCH 4 - PROGRESS: at 36.24% examples, 110983 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:21:21,728 : INFO : EPOCH 4 - PROGRESS: at 37.04% examples, 111004 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:22,832 : INFO : EPOCH 4 - PROGRESS: at 37.81% examples, 111057 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:23,916 : INFO : EPOCH 4 - PROGRESS: at 38.54% examples, 111022 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:21:24,966 : INFO : EPOCH 4 - PROGRESS: at 39.33% examples, 111182 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:25,999 : INFO : EPOCH 4 - PROGRESS: at 40.04% examples, 111226 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:27,006 : INFO : EPOCH 4 - PROGRESS: at 40.72% examples, 111208 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:28,111 : INFO : EPOCH 4 - PROGRESS: at 41.39% examples, 111011 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:29,173 : INFO : EPOCH 4 - PROGRESS: at 42.14% examples, 111025 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:30,221 : INFO : EPOCH 4 - PROGRESS: at 42.84% examples, 111056 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:31,239 : INFO : EPOCH 4 - PROGRESS: at 43.54% examples, 111031 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:32,285 : INFO : EPOCH 4 - PROGRESS: at 44.24% examples, 111055 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:33,371 : INFO : EPOCH 4 - PROGRESS: at 44.96% examples, 111025 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:34,471 : INFO : EPOCH 4 - PROGRESS: at 45.71% examples, 110967 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:35,540 : INFO : EPOCH 4 - PROGRESS: at 46.50% examples, 111080 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:36,562 : INFO : EPOCH 4 - PROGRESS: at 47.18% examples, 111046 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:37,588 : INFO : EPOCH 4 - PROGRESS: at 47.94% examples, 111115 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:38,599 : INFO : EPOCH 4 - PROGRESS: at 48.68% examples, 111103 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:39,639 : INFO : EPOCH 4 - PROGRESS: at 49.49% examples, 111157 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:40,672 : INFO : EPOCH 4 - PROGRESS: at 50.28% examples, 111211 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:41,692 : INFO : EPOCH 4 - PROGRESS: at 51.01% examples, 111190 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:42,775 : INFO : EPOCH 4 - PROGRESS: at 51.83% examples, 111159 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:43,801 : INFO : EPOCH 4 - PROGRESS: at 52.65% examples, 111224 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:44,835 : INFO : EPOCH 4 - PROGRESS: at 53.44% examples, 111272 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:45,850 : INFO : EPOCH 4 - PROGRESS: at 54.24% examples, 111260 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:46,912 : INFO : EPOCH 4 - PROGRESS: at 55.06% examples, 111266 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:47,932 : INFO : EPOCH 4 - PROGRESS: at 55.83% examples, 111339 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:48,999 : INFO : EPOCH 4 - PROGRESS: at 56.63% examples, 111340 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:21:50,000 : INFO : EPOCH 4 - PROGRESS: at 57.44% examples, 111433 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:51,015 : INFO : EPOCH 4 - PROGRESS: at 58.19% examples, 111408 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:52,064 : INFO : EPOCH 4 - PROGRESS: at 58.95% examples, 111421 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:53,110 : INFO : EPOCH 4 - PROGRESS: at 59.83% examples, 111445 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:54,173 : INFO : EPOCH 4 - PROGRESS: at 60.61% examples, 111462 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:55,214 : INFO : EPOCH 4 - PROGRESS: at 61.44% examples, 111495 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:56,271 : INFO : EPOCH 4 - PROGRESS: at 62.24% examples, 111500 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:57,455 : INFO : EPOCH 4 - PROGRESS: at 63.03% examples, 111434 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:58,541 : INFO : EPOCH 4 - PROGRESS: at 63.84% examples, 111420 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:21:59,582 : INFO : EPOCH 4 - PROGRESS: at 64.67% examples, 111449 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:00,629 : INFO : EPOCH 4 - PROGRESS: at 65.49% examples, 111476 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:01,668 : INFO : EPOCH 4 - PROGRESS: at 66.30% examples, 111511 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:02,684 : INFO : EPOCH 4 - PROGRESS: at 67.01% examples, 111489 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:03,701 : INFO : EPOCH 4 - PROGRESS: at 67.76% examples, 111467 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:04,752 : INFO : EPOCH 4 - PROGRESS: at 68.63% examples, 111488 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:05,820 : INFO : EPOCH 4 - PROGRESS: at 69.40% examples, 111489 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:06,838 : INFO : EPOCH 4 - PROGRESS: at 70.18% examples, 111529 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:07,839 : INFO : EPOCH 4 - PROGRESS: at 70.96% examples, 111534 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:08,895 : INFO : EPOCH 4 - PROGRESS: at 71.75% examples, 111555 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:09,896 : INFO : EPOCH 4 - PROGRESS: at 72.51% examples, 111550 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:10,954 : INFO : EPOCH 4 - PROGRESS: at 73.27% examples, 111549 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:11,974 : INFO : EPOCH 4 - PROGRESS: at 74.14% examples, 111601 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:13,041 : INFO : EPOCH 4 - PROGRESS: at 74.93% examples, 111596 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:22:14,067 : INFO : EPOCH 4 - PROGRESS: at 75.77% examples, 111635 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:15,086 : INFO : EPOCH 4 - PROGRESS: at 76.59% examples, 111691 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:16,205 : INFO : EPOCH 4 - PROGRESS: at 77.45% examples, 111709 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:17,216 : INFO : EPOCH 4 - PROGRESS: at 78.24% examples, 111703 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:18,304 : INFO : EPOCH 4 - PROGRESS: at 79.09% examples, 111749 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:19,362 : INFO : EPOCH 4 - PROGRESS: at 79.87% examples, 111750 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:20,399 : INFO : EPOCH 4 - PROGRESS: at 80.70% examples, 111811 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:21,403 : INFO : EPOCH 4 - PROGRESS: at 81.51% examples, 111846 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:22,457 : INFO : EPOCH 4 - PROGRESS: at 82.29% examples, 111846 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:23,515 : INFO : EPOCH 4 - PROGRESS: at 83.07% examples, 111847 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:24,556 : INFO : EPOCH 4 - PROGRESS: at 83.85% examples, 111870 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:25,560 : INFO : EPOCH 4 - PROGRESS: at 84.57% examples, 111799 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:26,616 : INFO : EPOCH 4 - PROGRESS: at 85.40% examples, 111810 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:27,657 : INFO : EPOCH 4 - PROGRESS: at 86.18% examples, 111834 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:28,716 : INFO : EPOCH 4 - PROGRESS: at 87.00% examples, 111868 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:29,762 : INFO : EPOCH 4 - PROGRESS: at 87.84% examples, 111870 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:30,745 : INFO : EPOCH 4 - PROGRESS: at 88.56% examples, 111802 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:31,798 : INFO : EPOCH 4 - PROGRESS: at 89.42% examples, 111871 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:32,882 : INFO : EPOCH 4 - PROGRESS: at 90.19% examples, 111849 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:22:33,937 : INFO : EPOCH 4 - PROGRESS: at 90.96% examples, 111876 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:34,986 : INFO : EPOCH 4 - PROGRESS: at 91.77% examples, 111890 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:36,026 : INFO : EPOCH 4 - PROGRESS: at 92.56% examples, 111924 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:37,034 : INFO : EPOCH 4 - PROGRESS: at 96.83% examples, 112226 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:37,611 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 20:22:37,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 20:22:37,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 20:22:37,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 20:22:37,709 : INFO : EPOCH - 4 : training on 19515612 raw words (14655628 effective words) took 130.2s, 112522 effective words/s\n",
            "2018-11-04 20:22:38,841 : INFO : EPOCH 5 - PROGRESS: at 0.65% examples, 93529 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:39,896 : INFO : EPOCH 5 - PROGRESS: at 1.36% examples, 102766 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:22:40,948 : INFO : EPOCH 5 - PROGRESS: at 2.07% examples, 106006 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:41,986 : INFO : EPOCH 5 - PROGRESS: at 2.77% examples, 107890 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:43,049 : INFO : EPOCH 5 - PROGRESS: at 3.46% examples, 108495 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:44,103 : INFO : EPOCH 5 - PROGRESS: at 4.19% examples, 109219 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:45,166 : INFO : EPOCH 5 - PROGRESS: at 4.93% examples, 109540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:46,228 : INFO : EPOCH 5 - PROGRESS: at 5.66% examples, 109914 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:22:47,247 : INFO : EPOCH 5 - PROGRESS: at 6.39% examples, 109813 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:48,281 : INFO : EPOCH 5 - PROGRESS: at 7.10% examples, 109521 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:49,308 : INFO : EPOCH 5 - PROGRESS: at 7.85% examples, 110047 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:50,324 : INFO : EPOCH 5 - PROGRESS: at 8.57% examples, 110544 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:51,366 : INFO : EPOCH 5 - PROGRESS: at 9.21% examples, 109746 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:52,421 : INFO : EPOCH 5 - PROGRESS: at 9.91% examples, 109943 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:53,451 : INFO : EPOCH 5 - PROGRESS: at 10.62% examples, 110297 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:54,454 : INFO : EPOCH 5 - PROGRESS: at 11.30% examples, 110346 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:55,464 : INFO : EPOCH 5 - PROGRESS: at 11.95% examples, 109955 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:22:56,523 : INFO : EPOCH 5 - PROGRESS: at 12.67% examples, 110050 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:57,640 : INFO : EPOCH 5 - PROGRESS: at 13.44% examples, 109805 words/s, in_qsize 8, out_qsize 1\n",
            "2018-11-04 20:22:58,653 : INFO : EPOCH 5 - PROGRESS: at 14.18% examples, 110186 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:22:59,711 : INFO : EPOCH 5 - PROGRESS: at 14.90% examples, 110260 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:00,734 : INFO : EPOCH 5 - PROGRESS: at 15.59% examples, 110488 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:01,778 : INFO : EPOCH 5 - PROGRESS: at 16.19% examples, 109991 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:02,805 : INFO : EPOCH 5 - PROGRESS: at 16.84% examples, 109955 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:23:03,891 : INFO : EPOCH 5 - PROGRESS: at 17.57% examples, 109923 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:04,960 : INFO : EPOCH 5 - PROGRESS: at 18.28% examples, 110040 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:06,033 : INFO : EPOCH 5 - PROGRESS: at 18.97% examples, 109994 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:07,102 : INFO : EPOCH 5 - PROGRESS: at 19.69% examples, 109990 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:08,128 : INFO : EPOCH 5 - PROGRESS: at 20.39% examples, 109898 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:09,208 : INFO : EPOCH 5 - PROGRESS: at 21.15% examples, 109910 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:10,269 : INFO : EPOCH 5 - PROGRESS: at 21.90% examples, 109979 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:11,298 : INFO : EPOCH 5 - PROGRESS: at 22.66% examples, 110361 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:12,414 : INFO : EPOCH 5 - PROGRESS: at 23.33% examples, 110010 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:23:13,655 : INFO : EPOCH 5 - PROGRESS: at 24.16% examples, 109888 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:14,693 : INFO : EPOCH 5 - PROGRESS: at 24.89% examples, 110009 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:15,762 : INFO : EPOCH 5 - PROGRESS: at 25.64% examples, 110033 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:16,775 : INFO : EPOCH 5 - PROGRESS: at 26.38% examples, 110216 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:17,796 : INFO : EPOCH 5 - PROGRESS: at 27.07% examples, 110167 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:18,993 : INFO : EPOCH 5 - PROGRESS: at 27.86% examples, 110031 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:20,036 : INFO : EPOCH 5 - PROGRESS: at 28.58% examples, 110136 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:21,085 : INFO : EPOCH 5 - PROGRESS: at 29.34% examples, 110211 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:22,139 : INFO : EPOCH 5 - PROGRESS: at 30.07% examples, 110255 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:23,173 : INFO : EPOCH 5 - PROGRESS: at 30.74% examples, 110196 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:24,234 : INFO : EPOCH 5 - PROGRESS: at 31.44% examples, 110222 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:25,282 : INFO : EPOCH 5 - PROGRESS: at 32.16% examples, 110291 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:26,356 : INFO : EPOCH 5 - PROGRESS: at 32.86% examples, 110283 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:27,456 : INFO : EPOCH 5 - PROGRESS: at 33.60% examples, 110206 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:28,540 : INFO : EPOCH 5 - PROGRESS: at 34.38% examples, 110178 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:23:29,636 : INFO : EPOCH 5 - PROGRESS: at 35.13% examples, 110144 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:23:30,677 : INFO : EPOCH 5 - PROGRESS: at 35.89% examples, 110227 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:31,751 : INFO : EPOCH 5 - PROGRESS: at 36.62% examples, 110228 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:32,831 : INFO : EPOCH 5 - PROGRESS: at 37.37% examples, 110219 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:33,963 : INFO : EPOCH 5 - PROGRESS: at 38.12% examples, 110236 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:23:34,980 : INFO : EPOCH 5 - PROGRESS: at 38.87% examples, 110351 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:36,038 : INFO : EPOCH 5 - PROGRESS: at 39.60% examples, 110364 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:37,071 : INFO : EPOCH 5 - PROGRESS: at 40.29% examples, 110307 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:38,146 : INFO : EPOCH 5 - PROGRESS: at 40.98% examples, 110302 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:39,158 : INFO : EPOCH 5 - PROGRESS: at 41.62% examples, 110168 words/s, in_qsize 4, out_qsize 3\n",
            "2018-11-04 20:23:40,212 : INFO : EPOCH 5 - PROGRESS: at 42.40% examples, 110329 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:41,275 : INFO : EPOCH 5 - PROGRESS: at 43.12% examples, 110354 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:42,445 : INFO : EPOCH 5 - PROGRESS: at 43.91% examples, 110293 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:43,491 : INFO : EPOCH 5 - PROGRESS: at 44.64% examples, 110453 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:44,577 : INFO : EPOCH 5 - PROGRESS: at 45.33% examples, 110316 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:45,655 : INFO : EPOCH 5 - PROGRESS: at 46.10% examples, 110313 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:23:46,703 : INFO : EPOCH 5 - PROGRESS: at 46.82% examples, 110352 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:47,771 : INFO : EPOCH 5 - PROGRESS: at 47.56% examples, 110370 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:23:48,816 : INFO : EPOCH 5 - PROGRESS: at 48.34% examples, 110424 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:23:49,907 : INFO : EPOCH 5 - PROGRESS: at 49.14% examples, 110401 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:50,951 : INFO : EPOCH 5 - PROGRESS: at 49.93% examples, 110455 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:51,973 : INFO : EPOCH 5 - PROGRESS: at 50.72% examples, 110540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:52,980 : INFO : EPOCH 5 - PROGRESS: at 51.47% examples, 110537 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:54,020 : INFO : EPOCH 5 - PROGRESS: at 52.27% examples, 110590 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:55,032 : INFO : EPOCH 5 - PROGRESS: at 53.06% examples, 110579 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:56,068 : INFO : EPOCH 5 - PROGRESS: at 53.82% examples, 110543 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:57,165 : INFO : EPOCH 5 - PROGRESS: at 54.64% examples, 110523 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:58,224 : INFO : EPOCH 5 - PROGRESS: at 55.54% examples, 110738 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:23:59,270 : INFO : EPOCH 5 - PROGRESS: at 56.21% examples, 110592 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:00,308 : INFO : EPOCH 5 - PROGRESS: at 57.03% examples, 110648 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:01,391 : INFO : EPOCH 5 - PROGRESS: at 57.88% examples, 110715 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:02,434 : INFO : EPOCH 5 - PROGRESS: at 58.67% examples, 110751 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:03,471 : INFO : EPOCH 5 - PROGRESS: at 59.44% examples, 110709 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:04,572 : INFO : EPOCH 5 - PROGRESS: at 60.28% examples, 110675 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:05,615 : INFO : EPOCH 5 - PROGRESS: at 61.06% examples, 110716 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:06,648 : INFO : EPOCH 5 - PROGRESS: at 61.89% examples, 110762 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:07,717 : INFO : EPOCH 5 - PROGRESS: at 62.68% examples, 110759 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:08,812 : INFO : EPOCH 5 - PROGRESS: at 63.44% examples, 110734 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:24:09,849 : INFO : EPOCH 5 - PROGRESS: at 64.25% examples, 110781 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:10,915 : INFO : EPOCH 5 - PROGRESS: at 65.08% examples, 110792 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:11,967 : INFO : EPOCH 5 - PROGRESS: at 65.87% examples, 110838 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:13,056 : INFO : EPOCH 5 - PROGRESS: at 66.67% examples, 110801 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:14,148 : INFO : EPOCH 5 - PROGRESS: at 67.51% examples, 110849 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:15,224 : INFO : EPOCH 5 - PROGRESS: at 68.35% examples, 110851 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:16,260 : INFO : EPOCH 5 - PROGRESS: at 69.16% examples, 110897 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:17,299 : INFO : EPOCH 5 - PROGRESS: at 69.93% examples, 110918 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:18,359 : INFO : EPOCH 5 - PROGRESS: at 70.75% examples, 110941 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:19,367 : INFO : EPOCH 5 - PROGRESS: at 71.56% examples, 111018 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:20,385 : INFO : EPOCH 5 - PROGRESS: at 72.32% examples, 111004 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:21,443 : INFO : EPOCH 5 - PROGRESS: at 73.05% examples, 110944 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:22,486 : INFO : EPOCH 5 - PROGRESS: at 73.87% examples, 110972 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:23,500 : INFO : EPOCH 5 - PROGRESS: at 74.65% examples, 110969 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:24,513 : INFO : EPOCH 5 - PROGRESS: at 75.44% examples, 111017 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:25,588 : INFO : EPOCH 5 - PROGRESS: at 76.26% examples, 111016 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:26,671 : INFO : EPOCH 5 - PROGRESS: at 77.08% examples, 111009 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:27,752 : INFO : EPOCH 5 - PROGRESS: at 77.88% examples, 111002 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:28,839 : INFO : EPOCH 5 - PROGRESS: at 78.73% examples, 110989 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:24:29,955 : INFO : EPOCH 5 - PROGRESS: at 79.52% examples, 110945 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:31,104 : INFO : EPOCH 5 - PROGRESS: at 80.33% examples, 110875 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:24:32,252 : INFO : EPOCH 5 - PROGRESS: at 81.20% examples, 110862 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:33,368 : INFO : EPOCH 5 - PROGRESS: at 81.98% examples, 110837 words/s, in_qsize 7, out_qsize 1\n",
            "2018-11-04 20:24:34,486 : INFO : EPOCH 5 - PROGRESS: at 82.77% examples, 110801 words/s, in_qsize 8, out_qsize 0\n",
            "2018-11-04 20:24:35,519 : INFO : EPOCH 5 - PROGRESS: at 83.49% examples, 110745 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:36,592 : INFO : EPOCH 5 - PROGRESS: at 84.26% examples, 110684 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:37,641 : INFO : EPOCH 5 - PROGRESS: at 84.97% examples, 110589 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:38,660 : INFO : EPOCH 5 - PROGRESS: at 85.76% examples, 110579 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:39,732 : INFO : EPOCH 5 - PROGRESS: at 86.49% examples, 110528 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:40,848 : INFO : EPOCH 5 - PROGRESS: at 87.29% examples, 110486 words/s, in_qsize 6, out_qsize 1\n",
            "2018-11-04 20:24:41,877 : INFO : EPOCH 5 - PROGRESS: at 88.11% examples, 110467 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:42,939 : INFO : EPOCH 5 - PROGRESS: at 88.88% examples, 110424 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:44,050 : INFO : EPOCH 5 - PROGRESS: at 89.61% examples, 110329 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:45,156 : INFO : EPOCH 5 - PROGRESS: at 90.39% examples, 110304 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:46,223 : INFO : EPOCH 5 - PROGRESS: at 91.18% examples, 110331 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:47,245 : INFO : EPOCH 5 - PROGRESS: at 91.98% examples, 110379 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:48,282 : INFO : EPOCH 5 - PROGRESS: at 93.05% examples, 110435 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:49,344 : INFO : EPOCH 5 - PROGRESS: at 97.68% examples, 110714 words/s, in_qsize 7, out_qsize 0\n",
            "2018-11-04 20:24:49,599 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-11-04 20:24:49,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-11-04 20:24:49,712 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-11-04 20:24:49,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-11-04 20:24:49,729 : INFO : EPOCH - 5 : training on 19515612 raw words (14652811 effective words) took 132.0s, 111008 effective words/s\n",
            "2018-11-04 20:24:49,732 : INFO : training on a 97578060 raw words (73270968 effective words) took 655.9s, 111708 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CA2cqTjHf2Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "365eb5cc-d476-42c6-eb88-141a562b3f7a"
      },
      "cell_type": "code",
      "source": [
        "# Let's see what we get\n",
        "\n",
        "model_toxic_fasttext.wv.most_similar('idiot', topn=20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-04 20:27:33,310 : INFO : precomputing L2-norms of word weight vectors\n",
            "2018-11-04 20:27:33,440 : INFO : precomputing L2-norms of ngram weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('iddiot', 0.9258104562759399),\n",
              " ('idiota', 0.89719557762146),\n",
              " ('idiom', 0.8744869232177734),\n",
              " ('idiote', 0.8390666246414185),\n",
              " ('idioma', 0.8310518264770508),\n",
              " ('idiocy', 0.7922382354736328),\n",
              " ('idio', 0.7896774411201477),\n",
              " ('idi', 0.7786841988563538),\n",
              " ('iot', 0.7639410495758057),\n",
              " ('idios', 0.7508178353309631),\n",
              " ('asshole', 0.7388148903846741),\n",
              " ('idiotic', 0.7024364471435547),\n",
              " ('idiots', 0.6875221729278564),\n",
              " ('ediot', 0.677729606628418),\n",
              " ('assh', 0.6772303581237793),\n",
              " ('idm', 0.6770260334014893),\n",
              " ('idw', 0.6714885234832764),\n",
              " ('idiotarian', 0.6597433090209961),\n",
              " ('idoit', 0.6562399864196777),\n",
              " ('idc', 0.6494848728179932)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "cVZhH9Ueiqo_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, fastText gives us a mix of semanticly similar and similar sounding words."
      ]
    },
    {
      "metadata": {
        "id": "BDFT9CY8afnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "20971350-a87d-4dfe-ba1f-e11c16ebb11c"
      },
      "cell_type": "code",
      "source": [
        "model_toxic_fasttext.save('model_fasttext.m')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-04 20:29:11,796 : INFO : saving FastText object under model_fasttext.m, separately None\n",
            "2018-11-04 20:29:11,798 : INFO : storing np array 'vectors_ngrams' to model_fasttext.m.wv.vectors_ngrams.npy\n",
            "2018-11-04 20:29:12,174 : INFO : not storing attribute vectors_ngrams_norm\n",
            "2018-11-04 20:29:12,177 : INFO : not storing attribute vectors_norm\n",
            "2018-11-04 20:29:12,178 : INFO : not storing attribute vectors_vocab_norm\n",
            "2018-11-04 20:29:12,180 : INFO : not storing attribute buckets_word\n",
            "2018-11-04 20:29:12,181 : INFO : storing np array 'vectors_ngrams_lockf' to model_fasttext.m.trainables.vectors_ngrams_lockf.npy\n",
            "2018-11-04 20:29:14,888 : INFO : saved model_fasttext.m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QqiHWQLccj8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hatespeech_tweets.to_pickle('hatespeech.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGtHVob5dLUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d148afd7-5b98-4f1f-d8c9-33ad0ac293e5"
      },
      "cell_type": "code",
      "source": [
        "!curl --upload-file hatespeech.p https://transfer.sh/hatespeech.p"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://transfer.sh/oG2hb/hatespeech.p"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}