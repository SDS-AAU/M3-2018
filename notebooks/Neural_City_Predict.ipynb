{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural City Predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/M3-2018/blob/master/notebooks/Neural_City_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jV-BaU11opWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's (neural) predict the continent given the Nomadlist Citydata from M1\n",
        "\n",
        "![nomad](https://cdn-images-1.medium.com/max/2000/1*CDiNeEaefU0BU6-R8ZY3hg.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "bjVaX-NoCFA_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's import data minging standard-libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# classification report\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTwyvcWVCMf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We can load the data directly out of the M1 repo\n",
        "\n",
        "data = pd.read_csv('https://github.com/SDS-AAU/M1-2018/raw/master/assignments/assignment_2/cities_predict.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0WIdlCopiq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "a988f96d-8833-46c8-e63d-01825c040c5f"
      },
      "cell_type": "code",
      "source": [
        "# A first look: Just to recap what was in the data:\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1br_studio_rent_in_center</th>\n",
              "      <th>adult_nightlife</th>\n",
              "      <th>air_quality_(year-round)</th>\n",
              "      <th>airbnb_(monthly)</th>\n",
              "      <th>cashless_society</th>\n",
              "      <th>coca-cola</th>\n",
              "      <th>coffee</th>\n",
              "      <th>cost_of_living</th>\n",
              "      <th>cost_of_living_for_expat</th>\n",
              "      <th>cost_of_living_for_local</th>\n",
              "      <th>...</th>\n",
              "      <th>religious_government</th>\n",
              "      <th>safe_tap_water</th>\n",
              "      <th>safety</th>\n",
              "      <th>startup_score</th>\n",
              "      <th>traffic_safety</th>\n",
              "      <th>walkability</th>\n",
              "      <th>nomad_score</th>\n",
              "      <th>region</th>\n",
              "      <th>country</th>\n",
              "      <th>place_slug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>492.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>946.0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.40</td>\n",
              "      <td>3.0</td>\n",
              "      <td>961.0</td>\n",
              "      <td>626.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>Latin America</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>mexico-city-mexico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>223.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.63</td>\n",
              "      <td>1.11</td>\n",
              "      <td>3.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.51</td>\n",
              "      <td>Latin America</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>cancun-mexico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>503.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1312.0</td>\n",
              "      <td>1.06622</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.70</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1064.0</td>\n",
              "      <td>631.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>Middle East</td>\n",
              "      <td>Jordan</td>\n",
              "      <td>amman-jordan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>426.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>885.0</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.41</td>\n",
              "      <td>3.0</td>\n",
              "      <td>789.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.83</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>ho-chi-minh-city-vietnam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2740.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>2135.0</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>1.06</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2801.0</td>\n",
              "      <td>2347.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.11</td>\n",
              "      <td>Asia</td>\n",
              "      <td>China</td>\n",
              "      <td>hong-kong-china</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1br_studio_rent_in_center  adult_nightlife  air_quality_(year-round)  \\\n",
              "0                      492.0              4.0                      42.0   \n",
              "1                      223.0              3.0                      19.0   \n",
              "2                      503.0              2.0                      68.0   \n",
              "3                      426.0              2.0                      23.0   \n",
              "4                     2740.0              2.0                      49.0   \n",
              "\n",
              "   airbnb_(monthly)  cashless_society  coca-cola  coffee  cost_of_living  \\\n",
              "0             946.0           1.00000       0.70    1.40             3.0   \n",
              "1             976.0           1.00000       0.63    1.11             3.0   \n",
              "2            1312.0           1.06622       0.54    0.70             3.0   \n",
              "3             885.0           2.00000       0.44    1.41             3.0   \n",
              "4            2135.0           3.00000       1.06    3.40             1.0   \n",
              "\n",
              "   cost_of_living_for_expat  cost_of_living_for_local  \\\n",
              "0                     961.0                     626.0   \n",
              "1                     697.0                     349.0   \n",
              "2                    1064.0                     631.0   \n",
              "3                     789.0                     522.0   \n",
              "4                    2801.0                    2347.0   \n",
              "\n",
              "             ...             religious_government  safe_tap_water  safety  \\\n",
              "0            ...                              0.0             0.0     1.0   \n",
              "1            ...                              0.0             0.0     2.0   \n",
              "2            ...                              1.0             0.0     3.0   \n",
              "3            ...                              0.0             0.0     3.0   \n",
              "4            ...                              0.0             0.0     3.0   \n",
              "\n",
              "   startup_score  traffic_safety  walkability  nomad_score         region  \\\n",
              "0            3.0             4.0          4.0         4.03  Latin America   \n",
              "1            3.0             4.0          4.0         4.51  Latin America   \n",
              "2            2.0             1.0          1.0         4.45    Middle East   \n",
              "3            3.0             3.0          4.0         4.83           Asia   \n",
              "4            4.0             3.0          4.0         4.11           Asia   \n",
              "\n",
              "   country                place_slug  \n",
              "0   Mexico        mexico-city-mexico  \n",
              "1   Mexico             cancun-mexico  \n",
              "2   Jordan              amman-jordan  \n",
              "3  Vietnam  ho-chi-minh-city-vietnam  \n",
              "4    China           hong-kong-china  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "YR-nskTkpabh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing for classification\n",
        "\n",
        "\"traditional\" classification algos. from Sklearn will behappy with a int-encoded variable as ```y``` but remember: **neural nets need a dummy matrix**"
      ]
    },
    {
      "metadata": {
        "id": "de1DYar7CQKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's encode our target variable \"Region\" into a number for the traditional classification (sklearn algo)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y = encoder.fit_transform(data['region'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXcQuw54CwG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cut out the input-data X and transform it into an array using .values\n",
        "\n",
        "X = data.loc[:,:'nomad_score'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INyt6TJPr4EI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b6ac9e16-fa07-471e-e3a8-22e865f472e8"
      },
      "cell_type": "code",
      "source": [
        "# A quick check if we need to scale the data:\n",
        "\n",
        "data.loc[:,:'nomad_score'].describe()\n",
        "\n",
        "# Obviousely we need to do that."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1br_studio_rent_in_center</th>\n",
              "      <th>adult_nightlife</th>\n",
              "      <th>air_quality_(year-round)</th>\n",
              "      <th>airbnb_(monthly)</th>\n",
              "      <th>cashless_society</th>\n",
              "      <th>coca-cola</th>\n",
              "      <th>coffee</th>\n",
              "      <th>cost_of_living</th>\n",
              "      <th>cost_of_living_for_expat</th>\n",
              "      <th>cost_of_living_for_local</th>\n",
              "      <th>...</th>\n",
              "      <th>peace</th>\n",
              "      <th>quality_of_life</th>\n",
              "      <th>racial_tolerance</th>\n",
              "      <th>religious_government</th>\n",
              "      <th>safe_tap_water</th>\n",
              "      <th>safety</th>\n",
              "      <th>startup_score</th>\n",
              "      <th>traffic_safety</th>\n",
              "      <th>walkability</th>\n",
              "      <th>nomad_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>730.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>656.096715</td>\n",
              "      <td>2.106849</td>\n",
              "      <td>40.608915</td>\n",
              "      <td>1711.775567</td>\n",
              "      <td>1.914128</td>\n",
              "      <td>1.338260</td>\n",
              "      <td>2.481932</td>\n",
              "      <td>2.187671</td>\n",
              "      <td>1444.247266</td>\n",
              "      <td>888.146074</td>\n",
              "      <td>...</td>\n",
              "      <td>2.489041</td>\n",
              "      <td>2.887671</td>\n",
              "      <td>2.138097</td>\n",
              "      <td>0.210959</td>\n",
              "      <td>0.475342</td>\n",
              "      <td>2.760274</td>\n",
              "      <td>2.927397</td>\n",
              "      <td>3.473973</td>\n",
              "      <td>3.272603</td>\n",
              "      <td>3.906561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>465.218067</td>\n",
              "      <td>0.358448</td>\n",
              "      <td>44.044073</td>\n",
              "      <td>941.886884</td>\n",
              "      <td>0.735266</td>\n",
              "      <td>0.869454</td>\n",
              "      <td>1.271214</td>\n",
              "      <td>0.868034</td>\n",
              "      <td>742.139699</td>\n",
              "      <td>506.694402</td>\n",
              "      <td>...</td>\n",
              "      <td>1.011872</td>\n",
              "      <td>0.360591</td>\n",
              "      <td>0.888359</td>\n",
              "      <td>0.408269</td>\n",
              "      <td>0.499734</td>\n",
              "      <td>0.904984</td>\n",
              "      <td>0.678043</td>\n",
              "      <td>0.948615</td>\n",
              "      <td>1.210806</td>\n",
              "      <td>0.432857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>62.510904</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>374.000000</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>314.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1098.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>1.442500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>792.000000</td>\n",
              "      <td>477.250000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.371214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>554.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1495.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.185000</td>\n",
              "      <td>2.405000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>803.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>870.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>2098.192785</td>\n",
              "      <td>2.244617</td>\n",
              "      <td>1.940000</td>\n",
              "      <td>3.467500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1962.250000</td>\n",
              "      <td>1199.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2783.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>368.000000</td>\n",
              "      <td>7839.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>8.610000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4147.000000</td>\n",
              "      <td>2980.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       1br_studio_rent_in_center  adult_nightlife  air_quality_(year-round)  \\\n",
              "count                 730.000000       730.000000                730.000000   \n",
              "mean                  656.096715         2.106849                 40.608915   \n",
              "std                   465.218067         0.358448                 44.044073   \n",
              "min                    62.510904         2.000000                  1.000000   \n",
              "25%                   314.250000         2.000000                 16.000000   \n",
              "50%                   554.000000         2.000000                 24.000000   \n",
              "75%                   870.750000         2.000000                 50.000000   \n",
              "max                  2783.000000         4.000000                368.000000   \n",
              "\n",
              "       airbnb_(monthly)  cashless_society   coca-cola      coffee  \\\n",
              "count        730.000000        730.000000  730.000000  730.000000   \n",
              "mean        1711.775567          1.914128    1.338260    2.481932   \n",
              "std          941.886884          0.735266    0.869454    1.271214   \n",
              "min          275.000000          1.000000    0.000000    0.000000   \n",
              "25%         1098.000000          1.000000    0.580000    1.442500   \n",
              "50%         1495.000000          2.000000    1.185000    2.405000   \n",
              "75%         2098.192785          2.244617    1.940000    3.467500   \n",
              "max         7839.000000          3.000000    5.000000    8.610000   \n",
              "\n",
              "       cost_of_living  cost_of_living_for_expat  cost_of_living_for_local  \\\n",
              "count      730.000000                730.000000                730.000000   \n",
              "mean         2.187671               1444.247266                888.146074   \n",
              "std          0.868034                742.139699                506.694402   \n",
              "min          1.000000                374.000000                177.000000   \n",
              "25%          1.000000                792.000000                477.250000   \n",
              "50%          2.000000               1302.000000                803.500000   \n",
              "75%          3.000000               1962.250000               1199.750000   \n",
              "max          4.000000               4147.000000               2980.000000   \n",
              "\n",
              "          ...            peace  quality_of_life  racial_tolerance  \\\n",
              "count     ...       730.000000       730.000000        730.000000   \n",
              "mean      ...         2.489041         2.887671          2.138097   \n",
              "std       ...         1.011872         0.360591          0.888359   \n",
              "min       ...         1.000000         1.000000          1.000000   \n",
              "25%       ...         2.000000         3.000000          1.371214   \n",
              "50%       ...         3.000000         3.000000          2.000000   \n",
              "75%       ...         3.000000         3.000000          3.000000   \n",
              "max       ...         4.000000         4.000000          4.000000   \n",
              "\n",
              "       religious_government  safe_tap_water      safety  startup_score  \\\n",
              "count            730.000000      730.000000  730.000000     730.000000   \n",
              "mean               0.210959        0.475342    2.760274       2.927397   \n",
              "std                0.408269        0.499734    0.904984       0.678043   \n",
              "min                0.000000        0.000000    1.000000       1.000000   \n",
              "25%                0.000000        0.000000    2.000000       3.000000   \n",
              "50%                0.000000        0.000000    3.000000       3.000000   \n",
              "75%                0.000000        1.000000    3.000000       3.000000   \n",
              "max                1.000000        1.000000    4.000000       4.000000   \n",
              "\n",
              "       traffic_safety  walkability  nomad_score  \n",
              "count      730.000000   730.000000   730.000000  \n",
              "mean         3.473973     3.272603     3.906561  \n",
              "std          0.948615     1.210806     0.432857  \n",
              "min          1.000000     1.000000     2.260000  \n",
              "25%          3.000000     2.000000     3.630000  \n",
              "50%          4.000000     4.000000     3.970000  \n",
              "75%          4.000000     4.000000     4.250000  \n",
              "max          4.000000     4.000000     4.970000  \n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "olCyu6KJCwfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Scaling the inputs using the sklearn standard scaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUaaWxuMDX2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split the data into train-test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTWtVteLss3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's run some baseline models\n",
        "\n",
        " - Logistic regression\n",
        " - XGboost"
      ]
    },
    {
      "metadata": {
        "id": "4bf7Sl0htgNR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "aBgnjQiADHcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "on5aVZ6ltKqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "74fda507-f414-4065-a284-1b7393d29635"
      },
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "B0m19pqLDOzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "32c7983c-0d1a-4d1f-d14a-748ac20505c0"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the results\n",
        "\n",
        "print('score:' + str(classifier.score(X_test, y_test)))\n",
        "print() #empty line\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score:0.8287671232876712\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.57      0.57      0.57         7\n",
            "          1       0.88      0.88      0.88        41\n",
            "          2       0.83      0.90      0.86        49\n",
            "          3       0.89      0.85      0.87        20\n",
            "          4       0.67      0.33      0.44         6\n",
            "          5       0.81      1.00      0.89        17\n",
            "          6       0.50      0.17      0.25         6\n",
            "\n",
            "avg / total       0.82      0.83      0.82       146\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4CeUeFdutizX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### XGBoost - eXtreme Gradient Boosting\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/dmlc/dmlc.github.io/master/img/logo-m/xgboost.png)\n",
        "\n",
        "XGBoost is a super efficient and popular algo (not from sklearn)\n",
        "read more  [here:](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)\n",
        "\n",
        "It will be hard to beat the result of that model (even using it \"out of the box\")"
      ]
    },
    {
      "metadata": {
        "id": "-fm8ANn3tlRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "classifier = XGBClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MB0hwmZ-tzD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "74e679ef-bd86-4324-aada-0f05cefb627c"
      },
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
              "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
              "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "       silent=True, subsample=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "9zTRRDYmuy7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "a635ec2e-2716-45f3-ac40-ed89c88de5f8"
      },
      "cell_type": "code",
      "source": [
        "print('score:' + str(classifier.score(X_test, y_test)))\n",
        "print() #empty line\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score:0.9041095890410958\n",
            "\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.75      0.86      0.80         7\n",
            "          1       0.93      0.95      0.94        41\n",
            "          2       0.89      0.98      0.93        49\n",
            "          3       0.89      0.85      0.87        20\n",
            "          4       1.00      0.33      0.50         6\n",
            "          5       0.94      1.00      0.97        17\n",
            "          6       1.00      0.50      0.67         6\n",
            "\n",
            "avg / total       0.91      0.90      0.90       146\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DnasLIh-vl0w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's prepare our output variable for the neural net model\n",
        "\n",
        "![alt text](https://www.machinelearningplus.com/wp-content/uploads/2018/03/one-hot-encoding.png)\n",
        "\n",
        "\n",
        "We need to create a dummy-matrix for our output-layer. In ML this is often called One Hot Encoding.\n",
        "\n",
        "Reverse transformation is easy (yet not too obvious) using: ```np.argmax(encoded_dummy_matrix, axis=1)```\n",
        "\n",
        "Given possible values 0, 1 and 2, the encoder transforms\n",
        "\n",
        "0: to 1, 0, 0\n",
        "1: to 0, 1, 0\n",
        "2: to 0, 0, 1\n",
        "\n",
        "np argmax will do the reverse. However, we have to remember that the neural net will not spit out 0/1 values but something like:\n",
        "\n",
        "```0.2, 0.6, 0.2```\n",
        "\n",
        "in that case we can say that the predicted class is 1. Why? Because the value at index 1 is highest."
      ]
    },
    {
      "metadata": {
        "id": "gcTqQHLQ2Phk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNt4D5n2F3Kl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import and instantiate the one hot encoder\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_enc = OneHotEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-jEL_MDxk1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remember that our initial y has to be reshaped from being a long vector with *n* elements to a 2D matrix of shape (n, 1)"
      ]
    },
    {
      "metadata": {
        "id": "QCV5KhePF0_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the dummy-matrix and reshaping (actually the other way around)\n",
        "\n",
        "y_matrix = one_hot_enc.fit_transform(y.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxGO7G1GGie_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create new train and test-splits\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_matrix, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bdiu1VEdGk72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36e70d3c-d9f5-48e3-8e89-a5112c37d875"
      },
      "cell_type": "code",
      "source": [
        "# Quick check of the created sets\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(584, 29)\n",
            "(584, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LFc2nZf1yRH_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's build a neural net\n",
        "\n",
        "![alt text](https://www.neuraldesigner.com/images/deep_neural_network.png)\n",
        "\n",
        "You can think about neural net architecture with Keras as of some sort of Lego.\n",
        "We will be building different layers with different bricks"
      ]
    },
    {
      "metadata": {
        "id": "Kct6Ri8bEgma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b47eaca3-1436-41b9-84e2-937978b9b385"
      },
      "cell_type": "code",
      "source": [
        "# Importing the keras library for deep learning\n",
        "\n",
        "# Essential elements of Keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Dropout layer\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Additional stuff: bells and whistles\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "op2uf_AjFRou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As in Sklearn and other models we instatiate the classifier first (nothing new here)\n",
        "classifier = Sequential() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngv5xHQO2l8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A bit on the below architecture**\n",
        "\n",
        "We start with an input layer, where we have to specify the input dimension: Here it is 29 because we have 29 variables for each observation (but actually you can pick what you feel like.)\n",
        "\n",
        "We add one hidden layer with 32 neurons. Just because (experiment with other numbers)!\n",
        "We also add 2 dropout layers. Here it will randomly freeze 30% of the hidden layer neurons each epoch. That step introduces random noise and prevents (to some extent) overfitting. Dropout is one very easy type of regularization.\n",
        "\n",
        "[More on Dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)\n",
        "\n",
        "We use relu as activation function\n",
        "\n",
        "Finally, we add our output layer with 7 units and use the softmax activation. More on activation functions below."
      ]
    },
    {
      "metadata": {
        "id": "TIM63BBWy9f4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From here we build up the network one layer at a time using the \"add\" method\n",
        "\n",
        "#### Input Layer ####\n",
        "classifier.add(Dense(units = 29, activation='relu', input_dim = 29))\n",
        "classifier.add(Dropout(rate = 0.3))\n",
        "\n",
        "#### Hidden ####\n",
        "classifier.add(Dense(units = 32, activation='relu'))\n",
        "classifier.add(Dropout(rate = 0.3))\n",
        "\n",
        "#### Output ####\n",
        "classifier.add(Dense(units = 7, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5taeKqetz8qh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**On ReLU and Softmax**\n",
        "\n",
        "ReLU stands for rectified linear unit and is defined as: y = max(0, x)\n",
        "It is the most used activation function for neural nets (today). A few years back the Hyperbolic tangent or Sigmoid funcitons have been very common but it turns out that ReLU performs better.\n",
        "\n",
        "You can read more on ReLU [here.](https://medium.com/tinymind/a-practical-guide-to-relu-b83ca804f1f7)\n",
        "\n",
        "\n",
        "In our output layer we use the Softmax function that outputs probabilities that sum up to 1. A great post on softmax and more material [here](https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d) \n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "h-6m17ki384R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now are done building the network but we are not finished. For it to run, we need to compile it.\n",
        "\n",
        "Here we need to specify the optimizer that we want to use. Here, we use the efficient \"Adam\" optimizer. The Adam optimization algorithm is an extension to stochastic gradient descen.t Read more on that [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
        "\n",
        "We also need to specify a loss function. Given that we are dealing with a multi-class classification problem, we pick categorical_crossentropy. Please check out the [Keras documentation](https://keras.io/losses/) for more info on loss functions.\n",
        "\n",
        "We evaluate accuracy during training"
      ]
    },
    {
      "metadata": {
        "id": "ymmrfHCtzQVt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### COMPILE ####\n",
        "classifier.compile(optimizer=\"adam\", loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GD8SJqD0FWLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4ecf7382-26fe-4405-9310-c4287e828967"
      },
      "cell_type": "code",
      "source": [
        "# Let's check out how our network looks like\n",
        "\n",
        "classifier.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 29)                870       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 29)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                960       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 231       \n",
            "=================================================================\n",
            "Total params: 2,061\n",
            "Trainable params: 2,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QP_-rQ1O6Cpo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now how do we get to the number of 2061 trainable parameters???\n",
        "\n",
        "Easy:\n",
        "\n",
        "in the first layer we have 29 neurons, looking at 29 inputs, that means 29 * 29 weights + 29 neurons that will assume some values.\n",
        "\n",
        "```29*29+29 = 870```\n",
        "\n",
        "```29*32+32 = 960```\n",
        "\n",
        "```32*7+7 = 231```"
      ]
    },
    {
      "metadata": {
        "id": "fLJcC1qV7MXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The checkpointer is not necessary but useful, as it will save the best performing model for later use\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_4HUyrVnG-I-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8534
        },
        "outputId": "053a2a68-695d-40f4-9929-7f25f38ce50e"
      },
      "cell_type": "code",
      "source": [
        "# We train the model with the fit method (surprise). We specify some parameters: how many observations per batch, how many epochs to train\n",
        "# the rest is optional but nice (calculate a test-set-performance score at each epoch, shuffle the observations in each batch as well as)\n",
        "# use the callback which saves the best model.\n",
        "history = classifier.fit(X_train, y_train, batch_size= 32, epochs= 250, validation_data=(X_test, y_test), shuffle=True,\n",
        "                        callbacks=[checkpointer])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 584 samples, validate on 146 samples\n",
            "Epoch 1/250\n",
            "584/584 [==============================] - 1s 2ms/step - loss: 2.1895 - acc: 0.1558 - val_loss: 1.9569 - val_acc: 0.1918\n",
            "Epoch 2/250\n",
            "584/584 [==============================] - 0s 268us/step - loss: 1.8881 - acc: 0.2363 - val_loss: 1.7478 - val_acc: 0.3082\n",
            "Epoch 3/250\n",
            "584/584 [==============================] - 0s 256us/step - loss: 1.6994 - acc: 0.3459 - val_loss: 1.5733 - val_acc: 0.4178\n",
            "Epoch 4/250\n",
            "584/584 [==============================] - 0s 276us/step - loss: 1.5428 - acc: 0.4127 - val_loss: 1.4316 - val_acc: 0.4795\n",
            "Epoch 5/250\n",
            "584/584 [==============================] - 0s 257us/step - loss: 1.4731 - acc: 0.4281 - val_loss: 1.3273 - val_acc: 0.5274\n",
            "Epoch 6/250\n",
            "584/584 [==============================] - 0s 262us/step - loss: 1.4021 - acc: 0.4384 - val_loss: 1.2657 - val_acc: 0.5753\n",
            "Epoch 7/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 1.3175 - acc: 0.5103 - val_loss: 1.2079 - val_acc: 0.6096\n",
            "Epoch 8/250\n",
            "584/584 [==============================] - 0s 236us/step - loss: 1.2387 - acc: 0.5411 - val_loss: 1.1648 - val_acc: 0.6370\n",
            "Epoch 9/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 1.2065 - acc: 0.5274 - val_loss: 1.1132 - val_acc: 0.6644\n",
            "Epoch 10/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 1.1588 - acc: 0.5942 - val_loss: 1.0807 - val_acc: 0.6438\n",
            "Epoch 11/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 1.1302 - acc: 0.5839 - val_loss: 1.0407 - val_acc: 0.6781\n",
            "Epoch 12/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 1.0936 - acc: 0.5890 - val_loss: 1.0142 - val_acc: 0.6918\n",
            "Epoch 13/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 1.0687 - acc: 0.5959 - val_loss: 0.9734 - val_acc: 0.6918\n",
            "Epoch 14/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 1.0940 - acc: 0.5976 - val_loss: 0.9487 - val_acc: 0.6986\n",
            "Epoch 15/250\n",
            "584/584 [==============================] - 0s 265us/step - loss: 1.0095 - acc: 0.6164 - val_loss: 0.9394 - val_acc: 0.6986\n",
            "Epoch 16/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.9864 - acc: 0.6507 - val_loss: 0.9109 - val_acc: 0.7055\n",
            "Epoch 17/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 1.0086 - acc: 0.6370 - val_loss: 0.8906 - val_acc: 0.6986\n",
            "Epoch 18/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.9719 - acc: 0.6644 - val_loss: 0.8691 - val_acc: 0.6986\n",
            "Epoch 19/250\n",
            "584/584 [==============================] - 0s 255us/step - loss: 0.9502 - acc: 0.6798 - val_loss: 0.8415 - val_acc: 0.7192\n",
            "Epoch 20/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.9474 - acc: 0.6490 - val_loss: 0.8214 - val_acc: 0.7055\n",
            "Epoch 21/250\n",
            "584/584 [==============================] - 0s 264us/step - loss: 0.8792 - acc: 0.6712 - val_loss: 0.7981 - val_acc: 0.7055\n",
            "Epoch 22/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.8516 - acc: 0.6832 - val_loss: 0.7860 - val_acc: 0.7123\n",
            "Epoch 23/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.8834 - acc: 0.6781 - val_loss: 0.7683 - val_acc: 0.7192\n",
            "Epoch 24/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.8226 - acc: 0.6832 - val_loss: 0.7538 - val_acc: 0.7123\n",
            "Epoch 25/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.7759 - acc: 0.7158 - val_loss: 0.7410 - val_acc: 0.7192\n",
            "Epoch 26/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.8075 - acc: 0.7158 - val_loss: 0.7237 - val_acc: 0.7329\n",
            "Epoch 27/250\n",
            "584/584 [==============================] - 0s 270us/step - loss: 0.7647 - acc: 0.7123 - val_loss: 0.7113 - val_acc: 0.7397\n",
            "Epoch 28/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.7737 - acc: 0.7123 - val_loss: 0.6963 - val_acc: 0.7534\n",
            "Epoch 29/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.7843 - acc: 0.7072 - val_loss: 0.6813 - val_acc: 0.7534\n",
            "Epoch 30/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.7320 - acc: 0.7449 - val_loss: 0.6747 - val_acc: 0.7808\n",
            "Epoch 31/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.7547 - acc: 0.7312 - val_loss: 0.6621 - val_acc: 0.7808\n",
            "Epoch 32/250\n",
            "584/584 [==============================] - 0s 252us/step - loss: 0.6836 - acc: 0.7586 - val_loss: 0.6428 - val_acc: 0.7808\n",
            "Epoch 33/250\n",
            "584/584 [==============================] - 0s 261us/step - loss: 0.7168 - acc: 0.7363 - val_loss: 0.6420 - val_acc: 0.7808\n",
            "Epoch 34/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.6953 - acc: 0.7551 - val_loss: 0.6306 - val_acc: 0.7877\n",
            "Epoch 35/250\n",
            "584/584 [==============================] - 0s 236us/step - loss: 0.7324 - acc: 0.7295 - val_loss: 0.6070 - val_acc: 0.8219\n",
            "Epoch 36/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.7074 - acc: 0.7449 - val_loss: 0.6042 - val_acc: 0.8151\n",
            "Epoch 37/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.6697 - acc: 0.7671 - val_loss: 0.5998 - val_acc: 0.8151\n",
            "Epoch 38/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.6687 - acc: 0.7500 - val_loss: 0.5970 - val_acc: 0.8151\n",
            "Epoch 39/250\n",
            "584/584 [==============================] - 0s 262us/step - loss: 0.6310 - acc: 0.7774 - val_loss: 0.5943 - val_acc: 0.8151\n",
            "Epoch 40/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.6361 - acc: 0.7877 - val_loss: 0.5828 - val_acc: 0.8151\n",
            "Epoch 41/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.6553 - acc: 0.7705 - val_loss: 0.5744 - val_acc: 0.8219\n",
            "Epoch 42/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.6299 - acc: 0.7808 - val_loss: 0.5692 - val_acc: 0.8082\n",
            "Epoch 43/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.6348 - acc: 0.7705 - val_loss: 0.5699 - val_acc: 0.8082\n",
            "Epoch 44/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.6127 - acc: 0.7654 - val_loss: 0.5625 - val_acc: 0.8082\n",
            "Epoch 45/250\n",
            "584/584 [==============================] - 0s 266us/step - loss: 0.5964 - acc: 0.7877 - val_loss: 0.5611 - val_acc: 0.8151\n",
            "Epoch 46/250\n",
            "584/584 [==============================] - 0s 233us/step - loss: 0.5752 - acc: 0.7928 - val_loss: 0.5490 - val_acc: 0.8151\n",
            "Epoch 47/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.5485 - acc: 0.7877 - val_loss: 0.5337 - val_acc: 0.8151\n",
            "Epoch 48/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.5630 - acc: 0.7860 - val_loss: 0.5307 - val_acc: 0.8219\n",
            "Epoch 49/250\n",
            "584/584 [==============================] - 0s 252us/step - loss: 0.5691 - acc: 0.8065 - val_loss: 0.5364 - val_acc: 0.8082\n",
            "Epoch 50/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.5816 - acc: 0.7945 - val_loss: 0.5383 - val_acc: 0.7945\n",
            "Epoch 51/250\n",
            "584/584 [==============================] - 0s 258us/step - loss: 0.5573 - acc: 0.8031 - val_loss: 0.5137 - val_acc: 0.8219\n",
            "Epoch 52/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.5687 - acc: 0.7928 - val_loss: 0.5171 - val_acc: 0.8288\n",
            "Epoch 53/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.5434 - acc: 0.8082 - val_loss: 0.5234 - val_acc: 0.8014\n",
            "Epoch 54/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.5284 - acc: 0.8116 - val_loss: 0.5269 - val_acc: 0.8082\n",
            "Epoch 55/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.5363 - acc: 0.8031 - val_loss: 0.5159 - val_acc: 0.8356\n",
            "Epoch 56/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.5054 - acc: 0.8185 - val_loss: 0.5053 - val_acc: 0.8288\n",
            "Epoch 57/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.5594 - acc: 0.7962 - val_loss: 0.5065 - val_acc: 0.8288\n",
            "Epoch 58/250\n",
            "584/584 [==============================] - 0s 265us/step - loss: 0.5141 - acc: 0.7945 - val_loss: 0.5041 - val_acc: 0.8288\n",
            "Epoch 59/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.5076 - acc: 0.8151 - val_loss: 0.4991 - val_acc: 0.8356\n",
            "Epoch 60/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.4606 - acc: 0.8527 - val_loss: 0.4860 - val_acc: 0.8356\n",
            "Epoch 61/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.4863 - acc: 0.8356 - val_loss: 0.4861 - val_acc: 0.8356\n",
            "Epoch 62/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.4666 - acc: 0.8305 - val_loss: 0.4781 - val_acc: 0.8356\n",
            "Epoch 63/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.5195 - acc: 0.8202 - val_loss: 0.4705 - val_acc: 0.8356\n",
            "Epoch 64/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.4799 - acc: 0.8339 - val_loss: 0.4614 - val_acc: 0.8493\n",
            "Epoch 65/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.4795 - acc: 0.8236 - val_loss: 0.4654 - val_acc: 0.8493\n",
            "Epoch 66/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.4500 - acc: 0.8271 - val_loss: 0.4555 - val_acc: 0.8425\n",
            "Epoch 67/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.4522 - acc: 0.8219 - val_loss: 0.4569 - val_acc: 0.8425\n",
            "Epoch 68/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.4757 - acc: 0.8271 - val_loss: 0.4578 - val_acc: 0.8425\n",
            "Epoch 69/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.4751 - acc: 0.8185 - val_loss: 0.4473 - val_acc: 0.8425\n",
            "Epoch 70/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.4404 - acc: 0.8596 - val_loss: 0.4386 - val_acc: 0.8562\n",
            "Epoch 71/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.4445 - acc: 0.8390 - val_loss: 0.4366 - val_acc: 0.8356\n",
            "Epoch 72/250\n",
            "584/584 [==============================] - 0s 236us/step - loss: 0.4508 - acc: 0.8288 - val_loss: 0.4334 - val_acc: 0.8425\n",
            "Epoch 73/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.4531 - acc: 0.8373 - val_loss: 0.4305 - val_acc: 0.8356\n",
            "Epoch 74/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.4340 - acc: 0.8442 - val_loss: 0.4302 - val_acc: 0.8630\n",
            "Epoch 75/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.4542 - acc: 0.8442 - val_loss: 0.4346 - val_acc: 0.8699\n",
            "Epoch 76/250\n",
            "584/584 [==============================] - 0s 235us/step - loss: 0.4737 - acc: 0.8356 - val_loss: 0.4317 - val_acc: 0.8493\n",
            "Epoch 77/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.5003 - acc: 0.8151 - val_loss: 0.4133 - val_acc: 0.8630\n",
            "Epoch 78/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.4621 - acc: 0.8459 - val_loss: 0.4212 - val_acc: 0.8699\n",
            "Epoch 79/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.4125 - acc: 0.8425 - val_loss: 0.4107 - val_acc: 0.8630\n",
            "Epoch 80/250\n",
            "584/584 [==============================] - 0s 256us/step - loss: 0.4377 - acc: 0.8356 - val_loss: 0.4202 - val_acc: 0.8630\n",
            "Epoch 81/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.4226 - acc: 0.8390 - val_loss: 0.4196 - val_acc: 0.8562\n",
            "Epoch 82/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.4581 - acc: 0.8253 - val_loss: 0.4245 - val_acc: 0.8562\n",
            "Epoch 83/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.4374 - acc: 0.8390 - val_loss: 0.4271 - val_acc: 0.8699\n",
            "Epoch 84/250\n",
            "584/584 [==============================] - 0s 259us/step - loss: 0.4442 - acc: 0.8630 - val_loss: 0.4324 - val_acc: 0.8630\n",
            "Epoch 85/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.4211 - acc: 0.8459 - val_loss: 0.4233 - val_acc: 0.8425\n",
            "Epoch 86/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.4151 - acc: 0.8527 - val_loss: 0.4199 - val_acc: 0.8562\n",
            "Epoch 87/250\n",
            "584/584 [==============================] - 0s 256us/step - loss: 0.3829 - acc: 0.8682 - val_loss: 0.4163 - val_acc: 0.8493\n",
            "Epoch 88/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.4173 - acc: 0.8596 - val_loss: 0.4125 - val_acc: 0.8493\n",
            "Epoch 89/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.4079 - acc: 0.8596 - val_loss: 0.4012 - val_acc: 0.8630\n",
            "Epoch 90/250\n",
            "584/584 [==============================] - 0s 257us/step - loss: 0.4106 - acc: 0.8545 - val_loss: 0.4027 - val_acc: 0.8425\n",
            "Epoch 91/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.3844 - acc: 0.8682 - val_loss: 0.4025 - val_acc: 0.8356\n",
            "Epoch 92/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.4392 - acc: 0.8476 - val_loss: 0.4043 - val_acc: 0.8493\n",
            "Epoch 93/250\n",
            "584/584 [==============================] - 0s 257us/step - loss: 0.4276 - acc: 0.8476 - val_loss: 0.3983 - val_acc: 0.8425\n",
            "Epoch 94/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.3515 - acc: 0.8904 - val_loss: 0.3973 - val_acc: 0.8630\n",
            "Epoch 95/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.3718 - acc: 0.8596 - val_loss: 0.3895 - val_acc: 0.8562\n",
            "Epoch 96/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3853 - acc: 0.8545 - val_loss: 0.3864 - val_acc: 0.8562\n",
            "Epoch 97/250\n",
            "584/584 [==============================] - 0s 255us/step - loss: 0.3645 - acc: 0.8818 - val_loss: 0.3894 - val_acc: 0.8562\n",
            "Epoch 98/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.3825 - acc: 0.8510 - val_loss: 0.3898 - val_acc: 0.8630\n",
            "Epoch 99/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.3721 - acc: 0.8579 - val_loss: 0.3886 - val_acc: 0.8493\n",
            "Epoch 100/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.3572 - acc: 0.8750 - val_loss: 0.3839 - val_acc: 0.8562\n",
            "Epoch 101/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.4059 - acc: 0.8442 - val_loss: 0.3777 - val_acc: 0.8699\n",
            "Epoch 102/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.3804 - acc: 0.8630 - val_loss: 0.3930 - val_acc: 0.8699\n",
            "Epoch 103/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.3488 - acc: 0.8716 - val_loss: 0.3948 - val_acc: 0.8425\n",
            "Epoch 104/250\n",
            "584/584 [==============================] - 0s 255us/step - loss: 0.3549 - acc: 0.8784 - val_loss: 0.3921 - val_acc: 0.8562\n",
            "Epoch 105/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3708 - acc: 0.8596 - val_loss: 0.3940 - val_acc: 0.8562\n",
            "Epoch 106/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.3724 - acc: 0.8545 - val_loss: 0.3910 - val_acc: 0.8493\n",
            "Epoch 107/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.3439 - acc: 0.8853 - val_loss: 0.3821 - val_acc: 0.8630\n",
            "Epoch 108/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.3455 - acc: 0.8716 - val_loss: 0.3918 - val_acc: 0.8630\n",
            "Epoch 109/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.3901 - acc: 0.8784 - val_loss: 0.3847 - val_acc: 0.8562\n",
            "Epoch 110/250\n",
            "584/584 [==============================] - 0s 259us/step - loss: 0.4340 - acc: 0.8510 - val_loss: 0.3786 - val_acc: 0.8630\n",
            "Epoch 111/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.3565 - acc: 0.8767 - val_loss: 0.3731 - val_acc: 0.8630\n",
            "Epoch 112/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.3634 - acc: 0.8682 - val_loss: 0.3751 - val_acc: 0.8699\n",
            "Epoch 113/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.3667 - acc: 0.8647 - val_loss: 0.3729 - val_acc: 0.8562\n",
            "Epoch 114/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.3469 - acc: 0.8716 - val_loss: 0.3728 - val_acc: 0.8630\n",
            "Epoch 115/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.3721 - acc: 0.8664 - val_loss: 0.3691 - val_acc: 0.8630\n",
            "Epoch 116/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.3502 - acc: 0.8750 - val_loss: 0.3710 - val_acc: 0.8562\n",
            "Epoch 117/250\n",
            "584/584 [==============================] - 0s 269us/step - loss: 0.3559 - acc: 0.8699 - val_loss: 0.3696 - val_acc: 0.8562\n",
            "Epoch 118/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.3561 - acc: 0.8767 - val_loss: 0.3713 - val_acc: 0.8767\n",
            "Epoch 119/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.3662 - acc: 0.8699 - val_loss: 0.3697 - val_acc: 0.8767\n",
            "Epoch 120/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.2920 - acc: 0.9110 - val_loss: 0.3751 - val_acc: 0.8767\n",
            "Epoch 121/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.3216 - acc: 0.8699 - val_loss: 0.3661 - val_acc: 0.8699\n",
            "Epoch 122/250\n",
            "584/584 [==============================] - 0s 231us/step - loss: 0.3109 - acc: 0.8818 - val_loss: 0.3681 - val_acc: 0.8767\n",
            "Epoch 123/250\n",
            "584/584 [==============================] - 0s 272us/step - loss: 0.3543 - acc: 0.8836 - val_loss: 0.3775 - val_acc: 0.8699\n",
            "Epoch 124/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.2846 - acc: 0.9110 - val_loss: 0.3729 - val_acc: 0.8630\n",
            "Epoch 125/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.3362 - acc: 0.8938 - val_loss: 0.3683 - val_acc: 0.8630\n",
            "Epoch 126/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3083 - acc: 0.8921 - val_loss: 0.3737 - val_acc: 0.8562\n",
            "Epoch 127/250\n",
            "584/584 [==============================] - 0s 258us/step - loss: 0.3245 - acc: 0.8767 - val_loss: 0.3776 - val_acc: 0.8630\n",
            "Epoch 128/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.3197 - acc: 0.8836 - val_loss: 0.3688 - val_acc: 0.8562\n",
            "Epoch 129/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.3385 - acc: 0.8870 - val_loss: 0.3750 - val_acc: 0.8562\n",
            "Epoch 130/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.2838 - acc: 0.9041 - val_loss: 0.3710 - val_acc: 0.8630\n",
            "Epoch 131/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.3457 - acc: 0.8545 - val_loss: 0.3591 - val_acc: 0.8836\n",
            "Epoch 132/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.3375 - acc: 0.8682 - val_loss: 0.3640 - val_acc: 0.8699\n",
            "Epoch 133/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3339 - acc: 0.8853 - val_loss: 0.3660 - val_acc: 0.8767\n",
            "Epoch 134/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.2879 - acc: 0.9092 - val_loss: 0.3610 - val_acc: 0.8630\n",
            "Epoch 135/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.3199 - acc: 0.8784 - val_loss: 0.3583 - val_acc: 0.8836\n",
            "Epoch 136/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2947 - acc: 0.8904 - val_loss: 0.3520 - val_acc: 0.8767\n",
            "Epoch 137/250\n",
            "584/584 [==============================] - 0s 266us/step - loss: 0.3302 - acc: 0.8784 - val_loss: 0.3520 - val_acc: 0.8630\n",
            "Epoch 138/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3286 - acc: 0.8801 - val_loss: 0.3534 - val_acc: 0.8699\n",
            "Epoch 139/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.3008 - acc: 0.8921 - val_loss: 0.3595 - val_acc: 0.8767\n",
            "Epoch 140/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.3061 - acc: 0.8990 - val_loss: 0.3639 - val_acc: 0.8767\n",
            "Epoch 141/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.3194 - acc: 0.8955 - val_loss: 0.3571 - val_acc: 0.8767\n",
            "Epoch 142/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.3372 - acc: 0.8836 - val_loss: 0.3633 - val_acc: 0.8630\n",
            "Epoch 143/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.3228 - acc: 0.8853 - val_loss: 0.3547 - val_acc: 0.8836\n",
            "Epoch 144/250\n",
            "584/584 [==============================] - 0s 264us/step - loss: 0.3208 - acc: 0.8887 - val_loss: 0.3519 - val_acc: 0.8836\n",
            "Epoch 145/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.3107 - acc: 0.8973 - val_loss: 0.3633 - val_acc: 0.8836\n",
            "Epoch 146/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2720 - acc: 0.8990 - val_loss: 0.3660 - val_acc: 0.8836\n",
            "Epoch 147/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.2722 - acc: 0.9075 - val_loss: 0.3719 - val_acc: 0.8630\n",
            "Epoch 148/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.3149 - acc: 0.8818 - val_loss: 0.3718 - val_acc: 0.8630\n",
            "Epoch 149/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2642 - acc: 0.9195 - val_loss: 0.3551 - val_acc: 0.8904\n",
            "Epoch 150/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.2842 - acc: 0.8973 - val_loss: 0.3551 - val_acc: 0.8767\n",
            "Epoch 151/250\n",
            "584/584 [==============================] - 0s 265us/step - loss: 0.2614 - acc: 0.8938 - val_loss: 0.3703 - val_acc: 0.8630\n",
            "Epoch 152/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2517 - acc: 0.9024 - val_loss: 0.3704 - val_acc: 0.8767\n",
            "Epoch 153/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.2908 - acc: 0.8887 - val_loss: 0.3594 - val_acc: 0.8836\n",
            "Epoch 154/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2770 - acc: 0.8955 - val_loss: 0.3524 - val_acc: 0.8836\n",
            "Epoch 155/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2784 - acc: 0.9110 - val_loss: 0.3576 - val_acc: 0.8836\n",
            "Epoch 156/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.3006 - acc: 0.8955 - val_loss: 0.3631 - val_acc: 0.8699\n",
            "Epoch 157/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2933 - acc: 0.8887 - val_loss: 0.3593 - val_acc: 0.8767\n",
            "Epoch 158/250\n",
            "584/584 [==============================] - 0s 257us/step - loss: 0.2760 - acc: 0.8955 - val_loss: 0.3613 - val_acc: 0.8904\n",
            "Epoch 159/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.2738 - acc: 0.9058 - val_loss: 0.3573 - val_acc: 0.8767\n",
            "Epoch 160/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.3100 - acc: 0.8938 - val_loss: 0.3654 - val_acc: 0.8699\n",
            "Epoch 161/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.2999 - acc: 0.8955 - val_loss: 0.3625 - val_acc: 0.8767\n",
            "Epoch 162/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2588 - acc: 0.9024 - val_loss: 0.3559 - val_acc: 0.8699\n",
            "Epoch 163/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.2717 - acc: 0.9024 - val_loss: 0.3575 - val_acc: 0.8630\n",
            "Epoch 164/250\n",
            "584/584 [==============================] - 0s 252us/step - loss: 0.2233 - acc: 0.9229 - val_loss: 0.3588 - val_acc: 0.8562\n",
            "Epoch 165/250\n",
            "584/584 [==============================] - 0s 263us/step - loss: 0.3020 - acc: 0.8853 - val_loss: 0.3619 - val_acc: 0.8699\n",
            "Epoch 166/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.3094 - acc: 0.8904 - val_loss: 0.3623 - val_acc: 0.8699\n",
            "Epoch 167/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2752 - acc: 0.8955 - val_loss: 0.3458 - val_acc: 0.8767\n",
            "Epoch 168/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.2478 - acc: 0.9178 - val_loss: 0.3431 - val_acc: 0.8836\n",
            "Epoch 169/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2534 - acc: 0.9247 - val_loss: 0.3417 - val_acc: 0.8767\n",
            "Epoch 170/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.2612 - acc: 0.9110 - val_loss: 0.3432 - val_acc: 0.8904\n",
            "Epoch 171/250\n",
            "584/584 [==============================] - 0s 256us/step - loss: 0.2580 - acc: 0.9024 - val_loss: 0.3394 - val_acc: 0.8836\n",
            "Epoch 172/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2373 - acc: 0.9195 - val_loss: 0.3432 - val_acc: 0.8904\n",
            "Epoch 173/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.2563 - acc: 0.9110 - val_loss: 0.3317 - val_acc: 0.9041\n",
            "Epoch 174/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2862 - acc: 0.8973 - val_loss: 0.3326 - val_acc: 0.8973\n",
            "Epoch 175/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.2480 - acc: 0.9092 - val_loss: 0.3446 - val_acc: 0.8767\n",
            "Epoch 176/250\n",
            "584/584 [==============================] - 0s 255us/step - loss: 0.2459 - acc: 0.9041 - val_loss: 0.3473 - val_acc: 0.8904\n",
            "Epoch 177/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.2442 - acc: 0.9024 - val_loss: 0.3435 - val_acc: 0.8904\n",
            "Epoch 178/250\n",
            "584/584 [==============================] - 0s 262us/step - loss: 0.3113 - acc: 0.8801 - val_loss: 0.3457 - val_acc: 0.8973\n",
            "Epoch 179/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.2941 - acc: 0.8973 - val_loss: 0.3389 - val_acc: 0.8904\n",
            "Epoch 180/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.2393 - acc: 0.9161 - val_loss: 0.3415 - val_acc: 0.8973\n",
            "Epoch 181/250\n",
            "584/584 [==============================] - 0s 235us/step - loss: 0.2358 - acc: 0.9075 - val_loss: 0.3598 - val_acc: 0.8973\n",
            "Epoch 182/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.2786 - acc: 0.9075 - val_loss: 0.3683 - val_acc: 0.8904\n",
            "Epoch 183/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2947 - acc: 0.8887 - val_loss: 0.3512 - val_acc: 0.8973\n",
            "Epoch 184/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.2789 - acc: 0.9110 - val_loss: 0.3415 - val_acc: 0.8904\n",
            "Epoch 185/250\n",
            "584/584 [==============================] - 0s 266us/step - loss: 0.2675 - acc: 0.9024 - val_loss: 0.3447 - val_acc: 0.9041\n",
            "Epoch 186/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.2227 - acc: 0.9144 - val_loss: 0.3518 - val_acc: 0.8904\n",
            "Epoch 187/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.2675 - acc: 0.8973 - val_loss: 0.3568 - val_acc: 0.8836\n",
            "Epoch 188/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.2147 - acc: 0.9247 - val_loss: 0.3652 - val_acc: 0.8836\n",
            "Epoch 189/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2318 - acc: 0.9161 - val_loss: 0.3747 - val_acc: 0.8973\n",
            "Epoch 190/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2288 - acc: 0.9127 - val_loss: 0.3700 - val_acc: 0.9041\n",
            "Epoch 191/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2171 - acc: 0.9247 - val_loss: 0.3678 - val_acc: 0.8904\n",
            "Epoch 192/250\n",
            "584/584 [==============================] - 0s 264us/step - loss: 0.2291 - acc: 0.9195 - val_loss: 0.3686 - val_acc: 0.8904\n",
            "Epoch 193/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.2938 - acc: 0.9075 - val_loss: 0.3727 - val_acc: 0.8836\n",
            "Epoch 194/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.2485 - acc: 0.9247 - val_loss: 0.3713 - val_acc: 0.8904\n",
            "Epoch 195/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.2674 - acc: 0.9127 - val_loss: 0.3713 - val_acc: 0.8904\n",
            "Epoch 196/250\n",
            "584/584 [==============================] - 0s 237us/step - loss: 0.2768 - acc: 0.8955 - val_loss: 0.3676 - val_acc: 0.8973\n",
            "Epoch 197/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.2440 - acc: 0.9332 - val_loss: 0.3537 - val_acc: 0.9041\n",
            "Epoch 198/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.2553 - acc: 0.9092 - val_loss: 0.3584 - val_acc: 0.9041\n",
            "Epoch 199/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.2306 - acc: 0.9247 - val_loss: 0.3623 - val_acc: 0.8973\n",
            "Epoch 200/250\n",
            "584/584 [==============================] - 0s 258us/step - loss: 0.2411 - acc: 0.9178 - val_loss: 0.3723 - val_acc: 0.8973\n",
            "Epoch 201/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.2263 - acc: 0.9281 - val_loss: 0.3723 - val_acc: 0.8904\n",
            "Epoch 202/250\n",
            "584/584 [==============================] - 0s 259us/step - loss: 0.2134 - acc: 0.9281 - val_loss: 0.3697 - val_acc: 0.8973\n",
            "Epoch 203/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2300 - acc: 0.9281 - val_loss: 0.3827 - val_acc: 0.8904\n",
            "Epoch 204/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.2110 - acc: 0.9264 - val_loss: 0.3934 - val_acc: 0.8836\n",
            "Epoch 205/250\n",
            "584/584 [==============================] - 0s 256us/step - loss: 0.2391 - acc: 0.9092 - val_loss: 0.3874 - val_acc: 0.8904\n",
            "Epoch 206/250\n",
            "584/584 [==============================] - 0s 276us/step - loss: 0.2201 - acc: 0.9264 - val_loss: 0.3829 - val_acc: 0.8904\n",
            "Epoch 207/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.2134 - acc: 0.9247 - val_loss: 0.3909 - val_acc: 0.8836\n",
            "Epoch 208/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.2464 - acc: 0.9110 - val_loss: 0.3727 - val_acc: 0.8973\n",
            "Epoch 209/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2334 - acc: 0.9144 - val_loss: 0.3585 - val_acc: 0.9041\n",
            "Epoch 210/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2182 - acc: 0.9195 - val_loss: 0.3702 - val_acc: 0.8836\n",
            "Epoch 211/250\n",
            "584/584 [==============================] - 0s 239us/step - loss: 0.2339 - acc: 0.9144 - val_loss: 0.3746 - val_acc: 0.8904\n",
            "Epoch 212/250\n",
            "584/584 [==============================] - 0s 241us/step - loss: 0.2328 - acc: 0.9110 - val_loss: 0.3649 - val_acc: 0.9110\n",
            "Epoch 213/250\n",
            "584/584 [==============================] - 0s 267us/step - loss: 0.2230 - acc: 0.9212 - val_loss: 0.3698 - val_acc: 0.9041\n",
            "Epoch 214/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.2384 - acc: 0.9264 - val_loss: 0.3748 - val_acc: 0.8904\n",
            "Epoch 215/250\n",
            "584/584 [==============================] - 0s 249us/step - loss: 0.2275 - acc: 0.9264 - val_loss: 0.3701 - val_acc: 0.8836\n",
            "Epoch 216/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.2306 - acc: 0.9041 - val_loss: 0.3794 - val_acc: 0.8836\n",
            "Epoch 217/250\n",
            "584/584 [==============================] - 0s 258us/step - loss: 0.2438 - acc: 0.9110 - val_loss: 0.3688 - val_acc: 0.8904\n",
            "Epoch 218/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.1891 - acc: 0.9315 - val_loss: 0.3604 - val_acc: 0.8973\n",
            "Epoch 219/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.2191 - acc: 0.9092 - val_loss: 0.3601 - val_acc: 0.8973\n",
            "Epoch 220/250\n",
            "584/584 [==============================] - 0s 270us/step - loss: 0.2487 - acc: 0.8973 - val_loss: 0.3623 - val_acc: 0.8973\n",
            "Epoch 221/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.2350 - acc: 0.9178 - val_loss: 0.3668 - val_acc: 0.8973\n",
            "Epoch 222/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.2147 - acc: 0.9264 - val_loss: 0.3584 - val_acc: 0.9041\n",
            "Epoch 223/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.2124 - acc: 0.9264 - val_loss: 0.3473 - val_acc: 0.9041\n",
            "Epoch 224/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.2440 - acc: 0.9092 - val_loss: 0.3467 - val_acc: 0.9041\n",
            "Epoch 225/250\n",
            "584/584 [==============================] - 0s 247us/step - loss: 0.2162 - acc: 0.9247 - val_loss: 0.3530 - val_acc: 0.9041\n",
            "Epoch 226/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.2387 - acc: 0.9212 - val_loss: 0.3679 - val_acc: 0.8973\n",
            "Epoch 227/250\n",
            "584/584 [==============================] - 0s 269us/step - loss: 0.2181 - acc: 0.9247 - val_loss: 0.3753 - val_acc: 0.8904\n",
            "Epoch 228/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.1987 - acc: 0.9384 - val_loss: 0.3672 - val_acc: 0.8973\n",
            "Epoch 229/250\n",
            "584/584 [==============================] - 0s 243us/step - loss: 0.2125 - acc: 0.9332 - val_loss: 0.3614 - val_acc: 0.8904\n",
            "Epoch 230/250\n",
            "584/584 [==============================] - 0s 257us/step - loss: 0.2276 - acc: 0.9247 - val_loss: 0.3661 - val_acc: 0.8904\n",
            "Epoch 231/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2326 - acc: 0.9247 - val_loss: 0.3688 - val_acc: 0.8836\n",
            "Epoch 232/250\n",
            "584/584 [==============================] - 0s 236us/step - loss: 0.2066 - acc: 0.9212 - val_loss: 0.3720 - val_acc: 0.8904\n",
            "Epoch 233/250\n",
            "584/584 [==============================] - 0s 240us/step - loss: 0.2203 - acc: 0.9178 - val_loss: 0.3701 - val_acc: 0.9110\n",
            "Epoch 234/250\n",
            "584/584 [==============================] - 0s 268us/step - loss: 0.2324 - acc: 0.9127 - val_loss: 0.3699 - val_acc: 0.9041\n",
            "Epoch 235/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.2399 - acc: 0.9161 - val_loss: 0.3741 - val_acc: 0.8904\n",
            "Epoch 236/250\n",
            "584/584 [==============================] - 0s 260us/step - loss: 0.2272 - acc: 0.9127 - val_loss: 0.3771 - val_acc: 0.8904\n",
            "Epoch 237/250\n",
            "584/584 [==============================] - 0s 251us/step - loss: 0.2088 - acc: 0.9298 - val_loss: 0.3682 - val_acc: 0.8973\n",
            "Epoch 238/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2339 - acc: 0.9110 - val_loss: 0.3591 - val_acc: 0.8836\n",
            "Epoch 239/250\n",
            "584/584 [==============================] - 0s 245us/step - loss: 0.2188 - acc: 0.9247 - val_loss: 0.3581 - val_acc: 0.8904\n",
            "Epoch 240/250\n",
            "584/584 [==============================] - 0s 248us/step - loss: 0.2483 - acc: 0.9127 - val_loss: 0.3553 - val_acc: 0.8973\n",
            "Epoch 241/250\n",
            "584/584 [==============================] - 0s 255us/step - loss: 0.1982 - acc: 0.9264 - val_loss: 0.3677 - val_acc: 0.8904\n",
            "Epoch 242/250\n",
            "584/584 [==============================] - 0s 238us/step - loss: 0.2022 - acc: 0.9384 - val_loss: 0.3742 - val_acc: 0.8973\n",
            "Epoch 243/250\n",
            "584/584 [==============================] - 0s 232us/step - loss: 0.2186 - acc: 0.9229 - val_loss: 0.3880 - val_acc: 0.8904\n",
            "Epoch 244/250\n",
            "584/584 [==============================] - 0s 253us/step - loss: 0.1951 - acc: 0.9384 - val_loss: 0.3923 - val_acc: 0.8836\n",
            "Epoch 245/250\n",
            "584/584 [==============================] - 0s 254us/step - loss: 0.2132 - acc: 0.9092 - val_loss: 0.3814 - val_acc: 0.8973\n",
            "Epoch 246/250\n",
            "584/584 [==============================] - 0s 242us/step - loss: 0.2310 - acc: 0.9110 - val_loss: 0.3812 - val_acc: 0.8836\n",
            "Epoch 247/250\n",
            "584/584 [==============================] - 0s 246us/step - loss: 0.2058 - acc: 0.9401 - val_loss: 0.3861 - val_acc: 0.9041\n",
            "Epoch 248/250\n",
            "584/584 [==============================] - 0s 269us/step - loss: 0.2179 - acc: 0.9229 - val_loss: 0.3789 - val_acc: 0.9041\n",
            "Epoch 249/250\n",
            "584/584 [==============================] - 0s 250us/step - loss: 0.1950 - acc: 0.9264 - val_loss: 0.3807 - val_acc: 0.9041\n",
            "Epoch 250/250\n",
            "584/584 [==============================] - 0s 244us/step - loss: 0.1846 - acc: 0.9366 - val_loss: 0.3894 - val_acc: 0.8973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vbYUJIi3H-Xg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's plot our trainin process (we actually can look what happened as we were training)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SsKxkAj1HEh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "30a8ff89-2af6-4696-a301-4d3b35f67862"
      },
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa7889e1668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa78896da58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-XKPooq3IA9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the best model (lowest loss)\n",
        "\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fNg3tAuK3pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48899a23-2c48-4e36-86ff-10f3bb107e39"
      },
      "cell_type": "code",
      "source": [
        "# How does it perform?\n",
        "\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146/146 [==============================] - 0s 534us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3316655685640361, 0.9041095865915899]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "biuDrNIMK_b9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "906c8d2f-0ed9-493c-fa2a-4d534507141d"
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.71      0.71      0.71         7\n",
            "          1       0.93      0.93      0.93        41\n",
            "          2       0.94      0.96      0.95        49\n",
            "          3       0.82      0.90      0.86        20\n",
            "          4       1.00      0.67      0.80         6\n",
            "          5       0.89      1.00      0.94        17\n",
            "          6       1.00      0.50      0.67         6\n",
            "\n",
            "avg / total       0.91      0.90      0.90       146\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VoInXugUBGLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "363b08fb-e3a8-40c9-f6ce-3fba45c3044e"
      },
      "cell_type": "code",
      "source": [
        "# columns = predicted, rows = real\n",
        "\n",
        "# y_test.A.ravel() is weird: we need to transform it from a matrix to an array and then flatten it back to a 1D vector.\n",
        "pd.crosstab(encoder.inverse_transform(y_test.A.ravel()),encoder.inverse_transform(y_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>Africa</th>\n",
              "      <th>Asia</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Latin America</th>\n",
              "      <th>Middle East</th>\n",
              "      <th>North America</th>\n",
              "      <th>Oceania</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Africa</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Asia</th>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Europe</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latin America</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Middle East</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>North America</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Oceania</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0          Africa  Asia  Europe  Latin America  Middle East  \\\n",
              "row_0                                                             \n",
              "Africa              5     2       0              0            0   \n",
              "Asia                0    38       1              2            0   \n",
              "Europe              0     0      47              1            0   \n",
              "Latin America       1     1       0             18            0   \n",
              "Middle East         1     0       0              1            4   \n",
              "North America       0     0       0              0            0   \n",
              "Oceania             0     0       2              0            0   \n",
              "\n",
              "col_0          North America  Oceania  \n",
              "row_0                                  \n",
              "Africa                     0        0  \n",
              "Asia                       0        0  \n",
              "Europe                     1        0  \n",
              "Latin America              0        0  \n",
              "Middle East                0        0  \n",
              "North America             17        0  \n",
              "Oceania                    1        3  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "BxOyXYWD_7NB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We clearly outperform the Logistic Regression and could probably get even better results with more optimization...at the same time we cannot beat XGBoost. But hey.\n",
        "\n",
        "* Actually in my final run it's: 0.9041095890410958 for XGBoost vs 0.9041095865915899 for the neural net :-O\n",
        "\n",
        "![alt text](https://media.giphy.com/media/SfYTJuxdAbsVW/giphy.gif)"
      ]
    }
  ]
}